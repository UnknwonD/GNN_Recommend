{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8936db61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 경로 설정\n",
    "data_dir = \"./data/VL_csv/\"\n",
    "\n",
    "# CSV 파일 경로\n",
    "t_path = lambda name: os.path.join(data_dir, name)\n",
    "\n",
    "# CSV 로딩 함수\n",
    "def load_data():\n",
    "    traveler_df = pd.read_csv(t_path(\"tn_traveller_master_여행객 Master_E.csv\"))\n",
    "    place_df = pd.read_csv(t_path(\"tn_visit_area_info_방문지정보_E.csv\"))\n",
    "    activity_df = pd.read_csv(t_path(\"tn_activity_his_활동내역_E.csv\"))\n",
    "    lodge_df = pd.read_csv(t_path(\"tn_lodge_consume_his_숙박소비내역_E.csv\"))\n",
    "    move_df = pd.read_csv(t_path(\"tn_move_his_이동내역_E.csv\"))\n",
    "    mvmn_consume_df = pd.read_csv(t_path(\"tn_mvmn_consume_his_이동수단소비내역_E.csv\"))\n",
    "    travel_df = pd.read_csv(t_path(\"tn_travel_여행_E.csv\"))\n",
    "    return traveler_df, place_df, activity_df, lodge_df, move_df, mvmn_consume_df, travel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "e9ee7d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\daeho\\OneDrive\\문서\\GitHub\\GNN_Recommend\n",
      "Data Directory: ./data/VL_csv/\n",
      "Data Exist: True\n"
     ]
    }
   ],
   "source": [
    "# 지금 위치 확인\n",
    "current_dir = os.getcwd()\n",
    "print(f\"Current Directory: {current_dir}\")\n",
    "print(f\"Data Directory: {data_dir}\")\n",
    "print(f\"Data Exist: {os.path.exists(t_path('tn_visit_area_info_방문지정보_E.csv'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "913bdd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 문자 → 숫자 매핑\n",
    "def encode_column(series):\n",
    "    le = LabelEncoder()\n",
    "    return le.fit_transform(series.astype(str)), le\n",
    "\n",
    "def preprocess_traveler(df):\n",
    "    gender_map = {'남': 0, '여': 1}\n",
    "    df['GENDER'] = df['GENDER'].map(gender_map).fillna(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1692ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hetero_graph():\n",
    "    traveler_df, place_df, activity_df, lodge_df, move_df, mvmn_consume_df, travel_df = load_data()\n",
    "\n",
    "    data = HeteroData()\n",
    "\n",
    "    # 여행자 노드\n",
    "    traveler_df = traveler_df.drop_duplicates(subset=\"TRAVELER_ID\")\n",
    "    traveler_df = preprocess_traveler(traveler_df)\n",
    "    traveler_ids, traveler_encoder = encode_column(travel_df[\"TRAVELER_ID\"])\n",
    "    traveler_feats = traveler_df[[\"AGE_GRP\", \"GENDER\", \"MARR_STTS\"]].fillna(0).astype(float)\n",
    "    data['traveler'].x = torch.tensor(traveler_feats.values, dtype=torch.float)\n",
    "\n",
    "    # 장소 노드 (VISIT_AREA_ID)\n",
    "    place_ids, place_encoder = encode_column(place_df[\"VISIT_AREA_ID\"])\n",
    "    place_feats = place_df[[\"VISIT_ORDER\"]].fillna(0).astype(float)\n",
    "    data['place'].x = torch.tensor(place_feats.values, dtype=torch.float)\n",
    "\n",
    "    # 활동 노드 (ACTIVITY_TYPE_CD 기준)\n",
    "    activity_df = activity_df.drop_duplicates(subset=[\"TRAVEL_ID\", \"ACTIVITY_TYPE_CD\"])\n",
    "    activity_ids, activity_encoder = encode_column(activity_df[\"ACTIVITY_TYPE_CD\"])\n",
    "    activity_feats = activity_df[[\"ACTIVITY_TYPE_SEQ\"]].fillna(0).astype(float)\n",
    "    data['activity'].x = torch.tensor(activity_feats.values, dtype=torch.float)\n",
    "\n",
    "    # 숙소 노드 (LODGING_TYPE_CD 기준)\n",
    "    lodge_df = lodge_df.drop_duplicates(subset=[\"TRAVEL_ID\", \"LODGING_TYPE_CD\"])\n",
    "    lodge_ids, lodge_encoder = encode_column(lodge_df[\"LODGING_TYPE_CD\"])\n",
    "    lodge_feats = lodge_df[[\"LODGING_PAYMENT_SEQ\"]].fillna(0).astype(float)\n",
    "    data['lodge'].x = torch.tensor(lodge_feats.values, dtype=torch.float)\n",
    "\n",
    "    # 여행 ID - 여행자 매핑 테이블\n",
    "    travel_mapping = travel_df[['TRAVEL_ID', 'TRAVELER_ID']].dropna()\n",
    "\n",
    "    # 엣지: 여행자 → 장소\n",
    "    edge_df = place_df.merge(travel_mapping, on='TRAVEL_ID')\n",
    "    edge_df = edge_df[edge_df['TRAVELER_ID'].astype(str).isin(traveler_encoder.classes_)]\n",
    "    src = traveler_encoder.transform(edge_df['TRAVELER_ID'].astype(str))\n",
    "    dst = place_encoder.transform(edge_df['VISIT_AREA_ID'].astype(str))\n",
    "    data['traveler', 'visited', 'place'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "    # 엣지: 여행자 → 활동\n",
    "    edge_df = activity_df.merge(travel_mapping, on='TRAVEL_ID')\n",
    "    src = traveler_encoder.transform(edge_df['TRAVELER_ID'].astype(str))\n",
    "    dst = activity_encoder.transform(edge_df['ACTIVITY_TYPE_CD'].astype(str))\n",
    "    data['traveler', 'did', 'activity'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "    # 엣지: 여행자 → 숙소\n",
    "    edge_df = lodge_df.merge(travel_mapping, on='TRAVEL_ID')\n",
    "    src = traveler_encoder.transform(edge_df['TRAVELER_ID'])\n",
    "    dst = lodge_encoder.transform(edge_df['LODGING_TYPE_CD'].astype(str))\n",
    "    data['traveler', 'stayed_in', 'lodge'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "    # 엣지: 장소 → 장소 (이동 정보 기반 동선 연결)\n",
    "    move_df = move_df.dropna(subset=[\"START_VISIT_AREA_ID\", \"END_VISIT_AREA_ID\"])\n",
    "    src = place_encoder.transform(move_df[\"START_VISIT_AREA_ID\"].astype(str))\n",
    "    dst = place_encoder.transform(move_df[\"END_VISIT_AREA_ID\"].astype(str))\n",
    "    data['place', 'move_to', 'place'].edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
    "\n",
    "     # traveler 노드 self-loop 추가\n",
    "    num_travelers = data['traveler'].x.size(0)\n",
    "    self_loop_src = torch.arange(num_travelers, dtype=torch.long)\n",
    "    self_loop_dst = torch.arange(num_travelers, dtype=torch.long)\n",
    "    data['traveler', 'self_loop', 'traveler'].edge_index = torch.stack([self_loop_src, self_loop_dst], dim=0)\n",
    "\n",
    "\n",
    "    # 엣지 feature: 이동 수단 거리 or 비용\n",
    "    if 'DSTNC' in move_df.columns:\n",
    "        edge_attr = torch.tensor(move_df['DSTNC'].fillna(0).values, dtype=torch.float).unsqueeze(1)\n",
    "        data['place', 'move_to', 'place'].edge_attr = edge_attr\n",
    "\n",
    "    return data, place_encoder, traveler_encoder, activity_encoder, lodge_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2091af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  traveler={ x=[320, 3] },\n",
      "  place={ x=[2770, 1] },\n",
      "  activity={ x=[1348, 1] },\n",
      "  lodge={ x=[90, 1] },\n",
      "  (traveler, visited, place)={ edge_index=[2, 2770] },\n",
      "  (traveler, did, activity)={ edge_index=[2, 1348] },\n",
      "  (traveler, stayed_in, lodge)={ edge_index=[2, 90] },\n",
      "  (place, move_to, place)={ edge_index=[2, 0] },\n",
      "  (traveler, self_loop, traveler)={ edge_index=[2, 320] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hetero_data, place_encoder, traveler_encoder, activity_encoder, lodge_encoder = build_hetero_graph()\n",
    "print(hetero_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce5042",
   "metadata": {},
   "source": [
    "# GNN 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1ce2793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import HeteroConv, GATConv, SAGEConv, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b78cc65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNRecommender(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels=32, out_channels=16):\n",
    "        super(GNNRecommender, self).__init__()\n",
    "        self.metadata = metadata\n",
    "\n",
    "        # HeteroConv 1층\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('traveler', 'self_loop', 'traveler'): GATConv((-1, -1), hidden_channels, add_self_loops=True),\n",
    "            ('traveler', 'visited', 'place'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            ('traveler', 'did', 'activity'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            ('traveler', 'stayed_in', 'lodge'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "            ('place', 'move_to', 'place'): GATConv((-1, -1), hidden_channels, add_self_loops=False),\n",
    "        }, aggr='sum')\n",
    "\n",
    "        # 노드별 선형 변환\n",
    "        self.lin_dict = nn.ModuleDict({\n",
    "            node_type: Linear(hidden_channels, out_channels)\n",
    "            for node_type in metadata[0]\n",
    "        })\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # HeteroConv 적용\n",
    "        x_dict_updated = self.conv1(x_dict, edge_index_dict)\n",
    "\n",
    "        # 선형 변환 및 활성화 함수 적용\n",
    "        out_dict = {}\n",
    "        for node_type, x in x_dict_updated.items():\n",
    "            out_dict[node_type] = self.lin_dict[node_type](x.relu())\n",
    "        return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3c3fc2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'traveler': tensor([[ 1.7106, -1.9376,  1.3860,  ...,  0.8402, -0.5126,  0.1970],\n",
      "        [ 2.5951, -2.9942,  2.1778,  ...,  1.4861, -0.8253,  0.3602],\n",
      "        [ 2.5951, -2.9942,  2.1778,  ...,  1.4861, -0.8253,  0.3602],\n",
      "        ...,\n",
      "        [ 2.7170, -2.9505,  2.2162,  ...,  1.3829, -0.9025,  0.4142],\n",
      "        [ 2.5951, -2.9942,  2.1778,  ...,  1.4861, -0.8253,  0.3602],\n",
      "        [ 1.8155, -2.0093,  1.4891,  ...,  1.0361, -0.6694,  0.2886]],\n",
      "       grad_fn=<AddmmBackward0>), 'place': tensor([[-1.0511,  3.2328, -0.6404,  ..., -7.5083,  2.6533,  0.3972],\n",
      "        [-1.0511,  3.2328, -0.6404,  ..., -7.5083,  2.6533,  0.3972],\n",
      "        [-1.0511,  3.2328, -0.6404,  ..., -7.5083,  2.6533,  0.3972],\n",
      "        ...,\n",
      "        [ 0.0623, -0.1268, -0.0867,  ...,  0.1749, -0.1217, -0.0128],\n",
      "        [ 0.0623, -0.1268, -0.0867,  ...,  0.1749, -0.1217, -0.0128],\n",
      "        [ 0.0623, -0.1268, -0.0867,  ...,  0.1749, -0.1217, -0.0128]],\n",
      "       grad_fn=<AddmmBackward0>), 'activity': tensor([[ 2.9149,  0.8843,  6.8429,  ...,  4.9412,  1.5221, -2.4407],\n",
      "        [ 2.9102,  0.8851,  6.8132,  ...,  4.9330,  1.5120, -2.4258],\n",
      "        [ 2.9104,  0.8755,  6.8428,  ...,  4.9262,  1.5223, -2.4465],\n",
      "        ...,\n",
      "        [ 0.1011,  0.1089, -0.0247,  ..., -0.1226, -0.0224,  0.0721],\n",
      "        [ 0.1011,  0.1089, -0.0247,  ..., -0.1226, -0.0224,  0.0721],\n",
      "        [ 0.1011,  0.1089, -0.0247,  ..., -0.1226, -0.0224,  0.0721]],\n",
      "       grad_fn=<AddmmBackward0>), 'lodge': tensor([[ 1.3100, -1.6141,  0.9844,  ...,  2.8910,  4.5427,  0.2131],\n",
      "        [ 1.3837, -1.6209,  0.9277,  ...,  2.8347,  4.5567,  0.1822],\n",
      "        [ 1.3106, -1.5608,  0.9033,  ...,  2.7452,  4.3186,  0.2449],\n",
      "        ...,\n",
      "        [ 0.1621, -0.0189, -0.0563,  ...,  0.1063,  0.0505,  0.0782],\n",
      "        [ 0.1621, -0.0189, -0.0563,  ...,  0.1063,  0.0505,  0.0782],\n",
      "        [ 0.1621, -0.0189, -0.0563,  ...,  0.1063,  0.0505,  0.0782]],\n",
      "       grad_fn=<AddmmBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "metadata = hetero_data.metadata()\n",
    "model = GNNRecommender(metadata)\n",
    "out = model(hetero_data.x_dict, hetero_data.edge_index_dict)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b8aa9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnn_train.py - GNN 학습 루프\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "# 학습 함수 정의\n",
    "def train_gnn(data, epochs=10, lr=0.005):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 모델 생성 및 이동\n",
    "    model = GNNRecommender(data.metadata()).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = BCEWithLogitsLoss()\n",
    "\n",
    "    # 훈련용 edge (링크 예측 대상): traveler → place\n",
    "    edge_index = data['traveler', 'visited', 'place'].edge_index\n",
    "    num_nodes_traveler = data['traveler'].num_nodes\n",
    "    num_nodes_place = data['place'].num_nodes\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        # 양성 샘플 (실제 방문)\n",
    "        pos_edge = edge_index.t()\n",
    "\n",
    "        # 음성 샘플 (방문 안한 곳 랜덤 샘플링)\n",
    "        neg_edge = negative_sampling(\n",
    "            edge_index=edge_index,\n",
    "            num_nodes=(num_nodes_traveler, num_nodes_place),\n",
    "            num_neg_samples=pos_edge.size(0),\n",
    "            method='sparse').t()\n",
    "\n",
    "        # 병합\n",
    "        edge_label_index = torch.cat([pos_edge, neg_edge], dim=0)\n",
    "        edge_label = torch.cat([\n",
    "            torch.ones(pos_edge.size(0)),\n",
    "            torch.zeros(neg_edge.size(0))\n",
    "        ], dim=0).to(device)\n",
    "\n",
    "        # forward\n",
    "        x_dict = {k: v.to(device) for k, v in data.x_dict.items()}\n",
    "        edge_index_dict = {k: v.to(device) for k, v in data.edge_index_dict.items()}\n",
    "        out_dict = model(x_dict, edge_index_dict)\n",
    "\n",
    "        src_emb = out_dict.get('traveler', x_dict['traveler'])[edge_label_index[:, 0]]\n",
    "        dst_emb = out_dict['place'][edge_label_index[:, 1]]\n",
    "        print(src_emb.shape, dst_emb.shape)\n",
    "        pred = (src_emb * dst_emb).sum(dim=-1)\n",
    "        loss = criterion(pred, edge_label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "feeee290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gnn(data, epochs=10, lr=0.005):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # 모델 생성 및 이동\n",
    "    model = GNNRecommender(data.metadata(), hidden_channels=32, out_channels=16).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = BCEWithLogitsLoss()\n",
    "\n",
    "    # 훈련용 edge (링크 예측 대상): traveler → place\n",
    "    edge_index = data['traveler', 'visited', 'place'].edge_index.to(device)\n",
    "    num_nodes_traveler = data['traveler'].x.size(0)\n",
    "    num_nodes_place = data['place'].x.size(0)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        # 양성 샘플 (실제 방문)\n",
    "        pos_edge = edge_index.t()\n",
    "\n",
    "        # 음성 샘플 (방문 안한 곳 랜덤 샘플링)\n",
    "        neg_edge = negative_sampling(\n",
    "            edge_index=edge_index,\n",
    "            num_nodes=(num_nodes_traveler, num_nodes_place),\n",
    "            num_neg_samples=pos_edge.size(0),\n",
    "            method='sparse').t()\n",
    "\n",
    "        # 병합\n",
    "        edge_label_index = torch.cat([pos_edge, neg_edge], dim=0)\n",
    "        edge_label = torch.cat([\n",
    "            torch.ones(pos_edge.size(0), device=device),\n",
    "            torch.zeros(neg_edge.size(0), device=device)\n",
    "        ], dim=0)\n",
    "\n",
    "        # forward\n",
    "        x_dict = {k: v.to(device) for k, v in data.x_dict.items()}\n",
    "        edge_index_dict = {k: v.to(device) for k, v in data.edge_index_dict.items()}\n",
    "        out_dict = model(x_dict, edge_index_dict)\n",
    "        \n",
    "        # traveler와 place 노드의 임베딩 추출\n",
    "        src_emb = out_dict['traveler'][edge_label_index[:, 0]]\n",
    "        dst_emb = out_dict['place'][edge_label_index[:, 1]]\n",
    "\n",
    "        # 점수 계산 및 손실 함수 적용\n",
    "        pred = (src_emb * dst_emb).sum(dim=-1)\n",
    "        loss = criterion(pred, edge_label)\n",
    "\n",
    "        # 역전파 및 최적화\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5c4489af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 17.5068\n",
      "[Epoch 2] Loss: 7.1169\n",
      "[Epoch 3] Loss: 9.7600\n",
      "[Epoch 4] Loss: 9.5770\n",
      "[Epoch 5] Loss: 7.8286\n",
      "[Epoch 6] Loss: 5.3115\n",
      "[Epoch 7] Loss: 2.5463\n",
      "[Epoch 8] Loss: 1.1627\n",
      "[Epoch 9] Loss: 2.5066\n",
      "[Epoch 10] Loss: 0.5967\n",
      "[Epoch 11] Loss: 1.0457\n",
      "[Epoch 12] Loss: 1.4552\n",
      "[Epoch 13] Loss: 1.5375\n",
      "[Epoch 14] Loss: 1.2705\n",
      "[Epoch 15] Loss: 1.0298\n",
      "[Epoch 16] Loss: 0.6895\n",
      "[Epoch 17] Loss: 0.6087\n",
      "[Epoch 18] Loss: 1.0459\n",
      "[Epoch 19] Loss: 0.8062\n",
      "[Epoch 20] Loss: 0.5370\n"
     ]
    }
   ],
   "source": [
    "model = train_gnn(hetero_data, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6bb1ef4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_topk_places(model, data, traveler_id, place_encoder, top_k=5):\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    # traveler ID 인덱스 변환\n",
    "    traveler_idx = traveler_encoder.transform([traveler_id])[0]\n",
    "\n",
    "    # 데이터 준비\n",
    "    x_dict = {k: v.to(device) for k, v in data.x_dict.items()}\n",
    "    edge_index_dict = {k: v.to(device) for k, v in data.edge_index_dict.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out_dict = model(x_dict, edge_index_dict)\n",
    "\n",
    "        # traveler 임베딩\n",
    "        traveler_emb = out_dict['traveler'][traveler_idx].unsqueeze(0)  # shape [1, d]\n",
    "        place_emb = out_dict['place']  # shape [N, d]\n",
    "\n",
    "        print(\"Traveler embedding sample:\", traveler_emb[0][:5])\n",
    "        print(\"Place embedding variance:\", place_emb.var(dim=0).mean())\n",
    "\n",
    "        # 내적 기반 유사도 계산\n",
    "        scores = (traveler_emb @ place_emb.T).squeeze(0)  # shape [N]\n",
    "        topk = torch.topk(scores, k=top_k)\n",
    "\n",
    "        top_indices = topk.indices.cpu().tolist()\n",
    "        top_scores = topk.values.cpu().tolist()\n",
    "\n",
    "    return list(zip(top_indices, top_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2369fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traveler embedding sample: tensor([-0.9857, -0.1818,  0.1061,  0.0718,  0.2792], device='cuda:0')\n",
      "Place embedding variance: tensor(0.3773, device='cuda:0')\n",
      "추천 장소 ID: 779, 점수: 5.5825\n",
      "추천 장소 ID: 98, 점수: 5.5825\n",
      "추천 장소 ID: 780, 점수: 5.5825\n",
      "추천 장소 ID: 782, 점수: 5.5825\n",
      "추천 장소 ID: 781, 점수: 5.5825\n"
     ]
    }
   ],
   "source": [
    "result = recommend_topk_places(model, hetero_data, 'e000297', place_encoder, top_k=5)\n",
    "for place_idx, score in result:\n",
    "    print(f\"추천 장소 ID: {place_idx}, 점수: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8c503164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 장소: 아우어 베이커리 하남 스타필드점 (인덱스 779), 점수: 5.5825\n",
      "추천 장소: 허 서방 불고기 냉면 (인덱스 98), 점수: 5.5825\n",
      "추천 장소: 집 (인덱스 780), 점수: 5.5825\n",
      "추천 장소: 이제 제 하남 스타필드점 (인덱스 782), 점수: 5.5825\n",
      "추천 장소: 안스 베이커리 스타필드 하남점 (인덱스 781), 점수: 5.5825\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "place_df = pd.read_csv(\"./data/VL_CSV/tn_visit_area_info_방문지정보_E.csv\")\n",
    "id_to_place = dict(zip(place_encoder.transform(place_df['VISIT_AREA_ID'].astype(str)), place_df['VISIT_AREA_NM']))\n",
    "\n",
    "for idx, score in result:\n",
    "    place_name = id_to_place.get(idx, \"Unknown\")\n",
    "    print(f\"추천 장소: {place_name} (인덱스 {idx}), 점수: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recommend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
