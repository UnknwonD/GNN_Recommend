{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 피드백 기반 경로 대체 테스트 시작!\n",
      "============================================================\n",
      "📱 사용 디바이스: cpu\n",
      "\n",
      "🗓️ 초기 여행 일정 (최적화):\n",
      "\n",
      "📅 Day 1:\n",
      " - [634] 그랜드 인터컨티넨탈 서울 파르나스\n",
      " - [2399] 그랜드 하얏트 서울\n",
      " - [2367] 논 드라이\n",
      " - [7810] 보문사\n",
      " - [1799] 조약돌 숯불닭갈비\n",
      " - [3168] 경포대\n",
      " - [350] 이인 휴게소 천안 방향\n",
      "\n",
      "📅 Day 2:\n",
      " - [8094] 동구 공영주차빌딩\n",
      " - [5015] 사천 시외버스터미널\n",
      " - [184] 제주 국제공항\n",
      "\n",
      "🔄 피드백 라운드 1\n",
      "✅ 피드백 업데이트 완료: 좋아요 1개, 싫어요 2개\n",
      "\n",
      "🎯 피드백 반영 후 최적화된 여행 일정:\n",
      "\n",
      "📅 Day 1:\n",
      " - [4098] 잠실종합운동장\n",
      " - [982] 코엑스\n",
      " - [8233] 중랑 아트센터\n",
      " - [187] 서울시립미술관 서소문 본관\n",
      " - [9178] 인천 SSG 랜더스 필드\n",
      " - [432] 콩치노 콘크리트\n",
      " - [1446] 가평 뮤직 빌리지 음악 역 1939\n",
      " - [8200] 이재효 갤러리\n",
      " - [6217] 핑크 타이거\n",
      " - [184] 제주 국제공항\n",
      "\n",
      "🔄 피드백 라운드 2\n",
      "✅ 피드백 업데이트 완료: 좋아요 0개, 싫어요 2개\n",
      "\n",
      "🎯 피드백 반영 후 최적화된 여행 일정:\n",
      "\n",
      "📅 Day 1:\n",
      " - [8094] 동구 공영주차빌딩\n",
      " - [184] 제주 국제공항\n",
      "\n",
      "📅 Day 2:\n",
      " - [4097] 천안삼거리휴게소 서울 방향\n",
      " - [350] 이인 휴게소 천안 방향\n",
      " - [2101] 서울 갈산 초등학교 후문\n",
      " - [2399] 그랜드 하얏트 서울\n",
      " - [3047] 익지 장사\n",
      " - [8028] 대룡시장\n",
      " - [6684] 이마트 춘천점\n",
      " - [3168] 경포대\n",
      "\n",
      "🔄 피드백 라운드 3\n",
      "✅ 피드백 업데이트 완료: 좋아요 2개, 싫어요 1개\n",
      "\n",
      "🎯 피드백 반영 후 최적화된 여행 일정:\n",
      "\n",
      "📅 Day 1:\n",
      " - [570] 비케이 에너지 석산 주유소\n",
      " - [3264] CU 여의영무예다음점\n",
      " - [2043] 생극 농협 하나로마트\n",
      " - [8551] 광개토태왕 광장\n",
      " - [2399] 그랜드 하얏트 서울\n",
      " - [404] 글램비글램핑\n",
      " - [8028] 대룡시장\n",
      " - [4418] 동송전통시장\n",
      " - [3168] 경포대\n",
      " - [140] 네이처 빌\n",
      "\n",
      "✅ 사용자 피드백 기반 경로 대체 테스트 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GATConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedTravelGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, travel_context_dim, \n",
    "                 num_heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gat1 = GATConv(in_channels, hidden_channels // num_heads, \n",
    "                           heads=num_heads, dropout=dropout, concat=True)\n",
    "        self.gat2 = GATConv(hidden_channels, hidden_channels // num_heads, \n",
    "                           heads=num_heads, dropout=dropout, concat=True)\n",
    "        self.gat3 = GATConv(hidden_channels, out_channels, \n",
    "                           heads=1, dropout=dropout, concat=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.travel_encoder = nn.Sequential(\n",
    "            nn.Linear(travel_context_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.fusion_net = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.preference_head = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, data, travel_context, return_attention=False):\n",
    "        x = data['visit_area'].x\n",
    "        edge_index = data['visit_area', 'moved_to', 'visit_area'].edge_index\n",
    "        \n",
    "        x1 = self.gat1(x, edge_index)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        \n",
    "        x2 = self.gat2(x1, edge_index)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = F.relu(x2 + x1)\n",
    "        x2 = self.dropout(x2)\n",
    "        \n",
    "        graph_embedding = self.gat3(x2, edge_index)\n",
    "        graph_embedding = self.bn3(graph_embedding)\n",
    "        \n",
    "        travel_embedding = self.travel_encoder(travel_context)\n",
    "        travel_embedding_expanded = travel_embedding.expand(graph_embedding.size(0), -1)\n",
    "        \n",
    "        fused_features = torch.cat([graph_embedding, travel_embedding_expanded], dim=1)\n",
    "        final_embedding = self.fusion_net(fused_features)\n",
    "        \n",
    "        preference_scores = self.preference_head(final_embedding)\n",
    "        \n",
    "        return final_embedding, preference_scores\n",
    "\n",
    "class EnhancedDataProcessor:\n",
    "    def __init__(self):\n",
    "        self.visit_scaler = RobustScaler()\n",
    "        self.travel_scaler = StandardScaler()\n",
    "        \n",
    "    def process_visit_area_features(self, visit_area_df):\n",
    "        visit_area_df = visit_area_df.copy()\n",
    "        \n",
    "        # 좌표 결측치 처리\n",
    "        visit_area_df['X_COORD'] = visit_area_df['X_COORD'].fillna(visit_area_df['X_COORD'].mean())\n",
    "        visit_area_df['Y_COORD'] = visit_area_df['Y_COORD'].fillna(visit_area_df['Y_COORD'].mean())\n",
    "        visit_area_df['VISIT_CHC_REASON_CD'] = visit_area_df['VISIT_CHC_REASON_CD'].fillna(0)\n",
    "        \n",
    "        features = visit_area_df[['X_COORD', 'Y_COORD']].copy()\n",
    "        \n",
    "        # One-hot encoding\n",
    "        type_onehot = pd.get_dummies(visit_area_df['VISIT_AREA_TYPE_CD'], prefix='type')\n",
    "        reason_onehot = pd.get_dummies(visit_area_df['VISIT_CHC_REASON_CD'].fillna(0), prefix='reason')\n",
    "        \n",
    "        # 정규화된 만족도 점수\n",
    "        for col in ['DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION']:\n",
    "            visit_area_df[col] = visit_area_df[col].fillna(3)\n",
    "            visit_area_df[f'{col}_norm'] = (visit_area_df[col] - 1) / 4.0\n",
    "        \n",
    "        # 인기도 점수\n",
    "        visit_area_df['popularity_score'] = (\n",
    "            visit_area_df['DGSTFN_norm'] * 0.4 + \n",
    "            visit_area_df['REVISIT_INTENTION_norm'] * 0.3 + \n",
    "            visit_area_df['RCMDTN_INTENTION_norm'] * 0.3\n",
    "        )\n",
    "        \n",
    "        # 모든 특성 결합\n",
    "        features = pd.concat([\n",
    "            features, type_onehot, reason_onehot,\n",
    "            visit_area_df[['DGSTFN_norm', 'REVISIT_INTENTION_norm', 'RCMDTN_INTENTION_norm', 'popularity_score']]\n",
    "        ], axis=1)\n",
    "        \n",
    "        return self.visit_scaler.fit_transform(features.values.astype(np.float32))\n",
    "    \n",
    "    def create_enhanced_edges(self, move_df, visit_area_df):\n",
    "        edges = []\n",
    "        edge_weights = []\n",
    "        \n",
    "        for travel_id, group in move_df.groupby(\"TRAVEL_ID\"):\n",
    "            group = group.sort_values(\"TRIP_ID\").reset_index(drop=True)\n",
    "            \n",
    "            for i in range(1, len(group)):\n",
    "                from_id = group.loc[i-1, \"END_NEW_ID\"]\n",
    "                to_id = group.loc[i, \"END_NEW_ID\"]\n",
    "                \n",
    "                if pd.notna(from_id) and pd.notna(to_id):\n",
    "                    duration = group.loc[i, \"DURATION_MINUTES\"] if \"DURATION_MINUTES\" in group.columns else 0\n",
    "                    transport = group.loc[i, \"MVMN_CD_1\"] if \"MVMN_CD_1\" in group.columns else 0\n",
    "                    \n",
    "                    edges.append([int(from_id), int(to_id), duration, transport])\n",
    "                    edge_weights.append(1.0)  # 기본 가중치\n",
    "        \n",
    "        edges_df = pd.DataFrame(edges, columns=[\"FROM_ID\", \"TO_ID\", \"DURATION_MINUTES\", \"MVMN_CD_1\"])\n",
    "        \n",
    "        # 교통수단 원핫 인코딩\n",
    "        edges_df[\"MVMN_TYPE\"] = edges_df[\"MVMN_CD_1\"].apply(\n",
    "            lambda code: \"drive\" if code in [1,2,3] else \"public\" if code in [4,5,6,7,8,9,10,11,12,13,50] else \"other\"\n",
    "        )\n",
    "        edges_df[\"is_drive\"] = (edges_df[\"MVMN_TYPE\"] == \"drive\").astype(int)\n",
    "        edges_df[\"is_public\"] = (edges_df[\"MVMN_TYPE\"] == \"public\").astype(int)\n",
    "        edges_df[\"is_other\"] = (edges_df[\"MVMN_TYPE\"] == \"other\").astype(int)\n",
    "        \n",
    "        edge_index = torch.tensor(edges_df[[\"FROM_ID\", \"TO_ID\"]].values.T, dtype=torch.long)\n",
    "        edge_attr = torch.tensor(np.column_stack([\n",
    "            edges_df[[\"DURATION_MINUTES\"]].fillna(0).values,\n",
    "            edges_df[[\"is_drive\", \"is_public\", \"is_other\"]].values,\n",
    "            np.array(edge_weights).reshape(-1, 1)\n",
    "        ]), dtype=torch.float32)\n",
    "        \n",
    "        return edge_index, edge_attr\n",
    "\n",
    "class SmartRecommendationEngine:\n",
    "    def __init__(self, model, visit_area_df, device):\n",
    "        self.model = model\n",
    "        self.visit_area_df = visit_area_df\n",
    "        self.device = device\n",
    "        self.user_feedback_history = []\n",
    "        self.preference_weights = None\n",
    "        \n",
    "    def get_recommendations(self, data, travel_context, top_k=10, diversity_weight=0.3, \n",
    "                          excluded_ids=None):\n",
    "        \"\"\"\n",
    "        다양성을 고려한 추천 (제외할 ID 목록 지원)\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings, preference_scores = self.model(data, travel_context)\n",
    "            \n",
    "        scores = preference_scores.squeeze()\n",
    "        \n",
    "        # 제외할 ID들을 낮은 점수로 설정\n",
    "        if excluded_ids:\n",
    "            for exclude_id in excluded_ids:\n",
    "                # visit_area_df에서 해당 ID의 인덱스 찾기\n",
    "                matching_indices = self.visit_area_df[\n",
    "                    self.visit_area_df['NEW_VISIT_AREA_ID'] == exclude_id\n",
    "                ].index.tolist()\n",
    "                \n",
    "                for idx in matching_indices:\n",
    "                    if idx < len(scores):\n",
    "                        scores[idx] = -1.0  # 매우 낮은 점수로 설정\n",
    "        \n",
    "        # 피드백 기반 점수 조정\n",
    "        if self.preference_weights is not None:\n",
    "            scores = self._apply_preference_weights(scores, embeddings)\n",
    "        \n",
    "        # MMR 기반 추천\n",
    "        recommendations = []\n",
    "        remaining_indices = list(range(len(scores)))\n",
    "        \n",
    "        # 제외된 인덱스들을 remaining_indices에서 제거\n",
    "        if excluded_ids:\n",
    "            for exclude_id in excluded_ids:\n",
    "                matching_indices = self.visit_area_df[\n",
    "                    self.visit_area_df['NEW_VISIT_AREA_ID'] == exclude_id\n",
    "                ].index.tolist()\n",
    "                for idx in matching_indices:\n",
    "                    if idx in remaining_indices:\n",
    "                        remaining_indices.remove(idx)\n",
    "        \n",
    "        # 첫 번째 추천\n",
    "        if remaining_indices:\n",
    "            valid_scores = [(i, scores[i].item()) for i in remaining_indices]\n",
    "            best_idx = max(valid_scores, key=lambda x: x[1])[0]\n",
    "            recommendations.append(best_idx)\n",
    "            remaining_indices.remove(best_idx)\n",
    "        \n",
    "        # 나머지 추천\n",
    "        for _ in range(min(top_k - 1, len(remaining_indices))):\n",
    "            if not remaining_indices:\n",
    "                break\n",
    "                \n",
    "            best_score = -float('inf')\n",
    "            best_idx = None\n",
    "            \n",
    "            for idx in remaining_indices:\n",
    "                relevance = scores[idx].item()\n",
    "                \n",
    "                if relevance < 0:  # 제외된 항목 스킵\n",
    "                    continue\n",
    "                \n",
    "                # 다양성 계산\n",
    "                similarities = []\n",
    "                for rec_idx in recommendations:\n",
    "                    sim = F.cosine_similarity(\n",
    "                        embeddings[idx:idx+1], \n",
    "                        embeddings[rec_idx:rec_idx+1]\n",
    "                    ).item()\n",
    "                    similarities.append(sim)\n",
    "                \n",
    "                diversity = 1 - max(similarities) if similarities else 1\n",
    "                final_score = (1 - diversity_weight) * relevance + diversity_weight * diversity\n",
    "                \n",
    "                if final_score > best_score:\n",
    "                    best_score = final_score\n",
    "                    best_idx = idx\n",
    "            \n",
    "            if best_idx is not None:\n",
    "                recommendations.append(best_idx)\n",
    "                remaining_indices.remove(best_idx)\n",
    "        \n",
    "        return recommendations, embeddings, preference_scores\n",
    "    \n",
    "    def _apply_preference_weights(self, scores, embeddings):\n",
    "        \"\"\"피드백 기반 점수 조정\"\"\"\n",
    "        if not self.preference_weights:\n",
    "            return scores\n",
    "            \n",
    "        # 선호 타입에 대한 가중치 적용\n",
    "        adjusted_scores = scores.clone()\n",
    "        \n",
    "        for i, row in self.visit_area_df.iterrows():\n",
    "            if i >= len(adjusted_scores):\n",
    "                break\n",
    "                \n",
    "            area_type = row.get('VISIT_AREA_TYPE_CD', 0)\n",
    "            \n",
    "            # 선호 타입이면 점수 증가\n",
    "            if area_type in self.preference_weights.get('preferred_types', []):\n",
    "                adjusted_scores[i] *= 1.2\n",
    "            \n",
    "            # 비선호 타입이면 점수 감소\n",
    "            if area_type in self.preference_weights.get('avoided_types', []):\n",
    "                adjusted_scores[i] *= 0.8\n",
    "        \n",
    "        return adjusted_scores\n",
    "    \n",
    "    def update_with_feedback(self, liked_items, disliked_items, embeddings):\n",
    "        \"\"\"사용자 피드백 업데이트\"\"\"\n",
    "        feedback = {\n",
    "            'liked': liked_items,\n",
    "            'disliked': disliked_items,\n",
    "            'embeddings': embeddings.cpu().numpy()\n",
    "        }\n",
    "        self.user_feedback_history.append(feedback)\n",
    "        \n",
    "        # 선호도 가중치 업데이트\n",
    "        self.preference_weights = self._calculate_preference_weights()\n",
    "        \n",
    "        print(f\"✅ 피드백 업데이트 완료: 좋아요 {len(liked_items)}개, 싫어요 {len(disliked_items)}개\")\n",
    "        \n",
    "        return self.preference_weights\n",
    "    \n",
    "    def _calculate_preference_weights(self):\n",
    "        \"\"\"피드백 히스토리를 바탕으로 선호도 가중치 계산\"\"\"\n",
    "        if not self.user_feedback_history:\n",
    "            return None\n",
    "            \n",
    "        liked_features = []\n",
    "        disliked_features = []\n",
    "        \n",
    "        for feedback in self.user_feedback_history:\n",
    "            for item_idx in feedback['liked']:\n",
    "                if item_idx < len(self.visit_area_df):\n",
    "                    liked_features.append(self.visit_area_df.iloc[item_idx])\n",
    "            \n",
    "            for item_idx in feedback['disliked']:\n",
    "                if item_idx < len(self.visit_area_df):\n",
    "                    disliked_features.append(self.visit_area_df.iloc[item_idx])\n",
    "        \n",
    "        preferred_types = [item.get('VISIT_AREA_TYPE_CD', 0) for item in liked_features]\n",
    "        avoided_types = [item.get('VISIT_AREA_TYPE_CD', 0) for item in disliked_features]\n",
    "        \n",
    "        return {\n",
    "            'preferred_types': list(set(preferred_types)),\n",
    "            'avoided_types': list(set(avoided_types)),\n",
    "            'preferred_regions': [(item.get('X_COORD', 0), item.get('Y_COORD', 0)) for item in liked_features]\n",
    "        }\n",
    "\n",
    "class OptimizedRouteGenerator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def generate_daily_routes(self, recommendations, visit_area_df, travel_duration, \n",
    "                            optimization_method='kmeans_tsp'):\n",
    "        \"\"\"일별 최적 경로 생성\"\"\"\n",
    "        if travel_duration <= 0:\n",
    "            travel_duration = 1\n",
    "            \n",
    "        coords = []\n",
    "        locations = []\n",
    "        \n",
    "        for idx in recommendations:\n",
    "            if idx < len(visit_area_df):\n",
    "                row = visit_area_df.iloc[idx]\n",
    "                coords.append([row['X_COORD'], row['Y_COORD']])\n",
    "                locations.append({\n",
    "                    'id': row['NEW_VISIT_AREA_ID'],\n",
    "                    'name': row['VISIT_AREA_NM'],\n",
    "                    'coords': [row['X_COORD'], row['Y_COORD']],\n",
    "                    'idx': idx,\n",
    "                    'type': row.get('VISIT_AREA_TYPE_CD', 0)\n",
    "                })\n",
    "        \n",
    "        if len(coords) == 0:\n",
    "            return {}\n",
    "            \n",
    "        coords = np.array(coords)\n",
    "        # NaN 처리 (예: 0으로 대체)\n",
    "        coords = np.nan_to_num(coords, nan=0.0)\n",
    "\n",
    "        \n",
    "        # K-means 클러스터링\n",
    "        n_clusters = min(travel_duration, len(locations))\n",
    "        if n_clusters > 1:\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            day_labels = kmeans.fit_predict(coords)\n",
    "        else:\n",
    "            day_labels = np.zeros(len(locations))\n",
    "        \n",
    "        # 클러스터 후 단일 Day 제거\n",
    "        daily_groups = {}\n",
    "        for i, loc in enumerate(locations):\n",
    "            day = int(day_labels[i])\n",
    "            if day not in daily_groups:\n",
    "                daily_groups[day] = []\n",
    "            daily_groups[day].append(loc)\n",
    "\n",
    "        # Day 단일 클러스터 제거: 최소 2개 이상으로 유지\n",
    "        for day, locs in list(daily_groups.items()):\n",
    "            if len(locs) == 1:\n",
    "                # Day1로 재배정\n",
    "                if 0 in daily_groups:\n",
    "                    daily_groups[0].extend(locs)\n",
    "                else:\n",
    "                    # Day1이 없으면 Day2로 합침\n",
    "                    target_day = next((d for d in daily_groups if d != day), 0)\n",
    "                    daily_groups[target_day].extend(locs)\n",
    "                del daily_groups[day]\n",
    "        \n",
    "        # TSP 최적화\n",
    "        optimized_routes = {}\n",
    "        for day, locations_day in daily_groups.items():\n",
    "            if len(locations_day) > 1:\n",
    "                optimized_order = self._solve_tsp_simple(locations_day)\n",
    "                optimized_routes[day] = optimized_order\n",
    "            else:\n",
    "                optimized_routes[day] = locations_day\n",
    "        \n",
    "        return optimized_routes\n",
    "    \n",
    "    def _solve_tsp_simple(self, locations):\n",
    "        \"\"\"간단한 TSP 해법\"\"\"\n",
    "        if len(locations) <= 2:\n",
    "            return locations\n",
    "            \n",
    "        coords = np.array([loc['coords'] for loc in locations])\n",
    "        n = len(coords)\n",
    "        \n",
    "        # 거리 행렬\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                dist_matrix[i][j] = np.linalg.norm(coords[i] - coords[j])\n",
    "        \n",
    "        # Nearest Neighbor\n",
    "        unvisited = set(range(1, n))\n",
    "        current = 0\n",
    "        route = [0]\n",
    "        \n",
    "        while unvisited:\n",
    "            nearest = min(unvisited, key=lambda x: dist_matrix[current][x])\n",
    "            route.append(nearest)\n",
    "            unvisited.remove(nearest)\n",
    "            current = nearest\n",
    "        \n",
    "        return [locations[i] for i in route]\n",
    "\n",
    "def process_travel_input(travel_info: dict):\n",
    "    \"\"\"여행 정보 전처리 함수\"\"\"\n",
    "    travel_feature_cols = [\n",
    "        'TOTAL_COST_BINNED_ENCODED', 'WITH_PET', 'MONTH', 'DURATION',\n",
    "        'MVMN_기타', 'MVMN_대중교통', 'MVMN_자가용',\n",
    "        'TRAVEL_PURPOSE_1', 'TRAVEL_PURPOSE_2', 'TRAVEL_PURPOSE_3',\n",
    "        'TRAVEL_PURPOSE_4', 'TRAVEL_PURPOSE_5', 'TRAVEL_PURPOSE_6',\n",
    "        'TRAVEL_PURPOSE_7', 'TRAVEL_PURPOSE_8', 'TRAVEL_PURPOSE_9',\n",
    "        'WHOWITH_2인여행', 'WHOWITH_가족여행', 'WHOWITH_기타',\n",
    "        'WHOWITH_단독여행', 'WHOWITH_친구/지인 여행'\n",
    "    ]\n",
    "    \n",
    "    # 반려동물 동반\n",
    "    travel_info['mission_ENC'] = travel_info['mission_ENC'].strip().split(',')\n",
    "    travel_info['WITH_PET'] = 1 if '0' in travel_info['mission_ENC'] else 0\n",
    "        \n",
    "    # 여행 목적\n",
    "    for i in range(1, 10):\n",
    "        travel_info[f'TRAVEL_PURPOSE_{i}'] = 1 if str(i) in travel_info['mission_ENC'] else 0\n",
    "        \n",
    "    # 날짜 처리\n",
    "    dates = travel_info['date_range'].split(' - ')\n",
    "    start_date = datetime.strptime(dates[0].strip(), \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(dates[1].strip(), \"%Y-%m-%d\")\n",
    "    \n",
    "    travel_info['MONTH'] = end_date.month\n",
    "    travel_info['DURATION'] = (end_date - start_date).days\n",
    "    \n",
    "    # 교통수단\n",
    "    for m in ['자가용', '대중교통', '기타']:\n",
    "        travel_info[f\"MVMN_{m}\"] = 0\n",
    "    \n",
    "    if travel_info['MVMN_NM_ENC'] == '1':\n",
    "        travel_info['MVMN_자가용'] = 1\n",
    "    elif travel_info['MVMN_NM_ENC'] == '2':\n",
    "        travel_info['MVMN_대중교통'] = 1\n",
    "    else:\n",
    "        travel_info['MVMN_기타'] = 1\n",
    "    \n",
    "    # 동행자\n",
    "    whowith_onehot = [0] * 5\n",
    "    idx = int(travel_info['whowith_ENC']) - 1\n",
    "    if 0 <= idx < 5:\n",
    "        whowith_onehot[idx] = 1\n",
    "    \n",
    "    travel_info.update({\n",
    "        'WHOWITH_단독여행': whowith_onehot[0],\n",
    "        'WHOWITH_2인여행': whowith_onehot[1],\n",
    "        'WHOWITH_가족여행': whowith_onehot[2],\n",
    "        'WHOWITH_친구/지인 여행': whowith_onehot[3],\n",
    "        'WHOWITH_기타': whowith_onehot[4],\n",
    "    })\n",
    "    \n",
    "    # 비용\n",
    "    travel_info['TOTAL_COST_BINNED_ENCODED'] = int(travel_info['TOTAL_COST'])\n",
    "    \n",
    "    # 최종 벡터 생성\n",
    "    travel_vector = [int(travel_info.get(k, 0)) for k in travel_feature_cols]\n",
    "    \n",
    "    return np.array([travel_vector]).astype(np.float32)\n",
    "\n",
    "def simulate_user_feedback():\n",
    "    \"\"\"사용자 피드백 시뮬레이션\"\"\"\n",
    "    feedback_options = [\n",
    "        {\"liked\": [], \"disliked\": [0, 2]},  # 첫 번째와 세 번째 장소 싫어요\n",
    "        {\"liked\": [1], \"disliked\": [4, 7]},  # 두 번째 장소 좋아요, 다른 곳들 싫어요\n",
    "        {\"liked\": [0, 3], \"disliked\": [5]},  # 복수 좋아요/싫어요\n",
    "    ]\n",
    "    \n",
    "    return random.choice(feedback_options)\n",
    "\n",
    "def main_feedback_test():\n",
    "    print(\"🚀 피드백 기반 경로 대체 테스트 시작!\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 기존 데이터 로딩\n",
    "    move_path = \"../data/VL_csv/move_with_new_id_final.csv\"\n",
    "    travel_path = \"tn_travel_processed.csv\"\n",
    "    visit_area_path = \"../data/VL_csv/visit_area_with_new_id_final.csv\"\n",
    "\n",
    "    move_df = pd.read_csv(move_path)\n",
    "    travel_df = pd.read_csv(travel_path)\n",
    "    visit_area_df = pd.read_csv(visit_area_path)\n",
    "\n",
    "    processor = EnhancedDataProcessor()\n",
    "    visit_area_tensor = processor.process_visit_area_features(visit_area_df)\n",
    "    edge_index, edge_attr = processor.create_enhanced_edges(move_df, visit_area_df)\n",
    "\n",
    "    data = HeteroData()\n",
    "    data['visit_area'].x = torch.tensor(visit_area_tensor, dtype=torch.float32)\n",
    "    data['visit_area', 'moved_to', 'visit_area'].edge_index = edge_index\n",
    "    data['visit_area', 'moved_to', 'visit_area'].edge_attr = edge_attr\n",
    "\n",
    "    # 여행 정보\n",
    "    travel_example = {\n",
    "        'mission_ENC': '0,1,2',\n",
    "        'date_range': '2025-09-28 - 2025-09-30',  # 3일 여행\n",
    "        'start_date': '',\n",
    "        'end_date': '',\n",
    "        'TOTAL_COST': '2',\n",
    "        'MVMN_NM_ENC': '2',\n",
    "        'whowith_ENC': '2',\n",
    "        'mission_type': 'normal'\n",
    "    }\n",
    "    travel_tensor = process_travel_input(travel_example)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"📱 사용 디바이스: {device}\")\n",
    "\n",
    "    model = ImprovedTravelGNN(\n",
    "        in_channels=visit_area_tensor.shape[1],\n",
    "        hidden_channels=128,\n",
    "        out_channels=64,\n",
    "        travel_context_dim=travel_tensor.shape[1],\n",
    "        num_heads=4,\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    data = data.to(device)\n",
    "    travel_context_tensor = torch.tensor(travel_tensor, dtype=torch.float32).to(device)\n",
    "    recommender = SmartRecommendationEngine(model, visit_area_df, device)\n",
    "\n",
    "    # 초기 추천 (중복 제거)\n",
    "    recommendations, embeddings, _ = recommender.get_recommendations(\n",
    "        data, travel_context_tensor, top_k=20, diversity_weight=0.3\n",
    "    )\n",
    "\n",
    "    # 중복 방문지 제거\n",
    "    unique_recommendations, seen_ids = [], set()\n",
    "    for idx in recommendations:\n",
    "        area_id = visit_area_df.iloc[idx]['NEW_VISIT_AREA_ID']\n",
    "        if area_id not in seen_ids and area_id != 0:\n",
    "            unique_recommendations.append(idx)\n",
    "            seen_ids.add(area_id)\n",
    "        if len(unique_recommendations) == 10:\n",
    "            break\n",
    "\n",
    "    # 최적화 경로 생성\n",
    "    route_generator = OptimizedRouteGenerator()\n",
    "    travel_duration = int(travel_tensor[0, 3])\n",
    "    optimized_routes = route_generator.generate_daily_routes(\n",
    "        unique_recommendations, visit_area_df, travel_duration\n",
    "    )\n",
    "\n",
    "    print(\"\\n🗓️ 초기 여행 일정 (최적화):\")\n",
    "    for day, route in sorted(optimized_routes.items()):\n",
    "        print(f\"\\n📅 Day {day + 1}:\")\n",
    "        for loc in route:\n",
    "            print(f\" - [{loc['id']:3d}] {loc['name']}\")\n",
    "\n",
    "    # 피드백 라운드 반복\n",
    "    for round_num in range(3):\n",
    "        print(f\"\\n🔄 피드백 라운드 {round_num + 1}\")\n",
    "        feedback = simulate_user_feedback()\n",
    "        liked_indices = [recommendations[i] for i in feedback[\"liked\"] if i < len(recommendations)]\n",
    "        disliked_indices = [recommendations[i] for i in feedback[\"disliked\"] if i < len(recommendations)]\n",
    "\n",
    "        recommender.update_with_feedback(liked_indices, disliked_indices, embeddings)\n",
    "\n",
    "        # 제외된 항목 반영\n",
    "        excluded_ids = {visit_area_df.iloc[idx]['NEW_VISIT_AREA_ID'] for idx in disliked_indices}\n",
    "        recommendations, embeddings, _ = recommender.get_recommendations(\n",
    "            data, travel_context_tensor, top_k=20, diversity_weight=0.3, excluded_ids=excluded_ids\n",
    "        )\n",
    "\n",
    "        unique_recommendations, seen_ids = [], set()\n",
    "        for idx in recommendations:\n",
    "            area_id = visit_area_df.iloc[idx]['NEW_VISIT_AREA_ID']\n",
    "            if area_id not in seen_ids and area_id not in excluded_ids and area_id != 0:\n",
    "                unique_recommendations.append(idx)\n",
    "                seen_ids.add(area_id)\n",
    "            if len(unique_recommendations) == 10:\n",
    "                break\n",
    "\n",
    "        optimized_routes = route_generator.generate_daily_routes(\n",
    "            unique_recommendations, visit_area_df, travel_duration\n",
    "        )\n",
    "\n",
    "        print(\"\\n🎯 피드백 반영 후 최적화된 여행 일정:\")\n",
    "        for day, route in sorted(optimized_routes.items()):\n",
    "            if len(route) < 2 and len(optimized_routes) > 1:\n",
    "                continue  # 단일 장소 Day 제거\n",
    "            print(f\"\\n📅 Day {day + 1}:\")\n",
    "            for loc in route:\n",
    "                print(f\" - [{loc['id']:3d}] {loc['name']}\")\n",
    "\n",
    "    print(\"\\n✅ 사용자 피드백 기반 경로 대체 테스트 완료!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_feedback_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 데이터 로딩 중...\n",
      "⚙️ 데이터 전처리 중...\n",
      "💾 파일 저장 중...\n",
      "✅ 저장 완료!\n",
      "- travel_recommendation_model.pt: 모델 파라미터\n",
      "- travel_data.pkl: 전처리된 데이터 및 스케일러\n"
     ]
    }
   ],
   "source": [
    "# save_model_and_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "def save_model_and_data():\n",
    "    \"\"\"모델과 필요한 데이터들을 저장\"\"\"\n",
    "    \n",
    "    # 1. 데이터 로딩\n",
    "    print(\"📊 데이터 로딩 중...\")\n",
    "    move_path = \"../data/VL_csv/move_with_new_id_final.csv\"\n",
    "    travel_path = \"tn_travel_processed.csv\"\n",
    "    visit_area_path = \"../data/VL_csv/visit_area_with_new_id_final.csv\"\n",
    "    \n",
    "    move_df = pd.read_csv(move_path)\n",
    "    travel_df = pd.read_csv(travel_path)\n",
    "    visit_area_df = pd.read_csv(visit_area_path)\n",
    "    \n",
    "    # 2. 데이터 전처리\n",
    "    print(\"⚙️ 데이터 전처리 중...\")\n",
    "    processor = EnhancedDataProcessor()\n",
    "    visit_area_tensor = processor.process_visit_area_features(visit_area_df)\n",
    "    edge_index, edge_attr = processor.create_enhanced_edges(move_df, visit_area_df)\n",
    "    \n",
    "    # 3. 그래프 데이터 생성\n",
    "    data = HeteroData()\n",
    "    data['visit_area'].x = torch.tensor(visit_area_tensor, dtype=torch.float32)\n",
    "    data['visit_area', 'moved_to', 'visit_area'].edge_index = edge_index\n",
    "    data['visit_area', 'moved_to', 'visit_area'].edge_attr = edge_attr\n",
    "    \n",
    "    # 4. 모델 초기화 (실제로는 학습된 모델을 사용)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ImprovedTravelGNN(\n",
    "        in_channels=visit_area_tensor.shape[1],\n",
    "        hidden_channels=128,\n",
    "        out_channels=64,\n",
    "        travel_context_dim=25,  # travel feature 개수\n",
    "        num_heads=4,\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "    \n",
    "    # 5. 저장할 데이터 준비\n",
    "    save_data = {\n",
    "        'visit_area_df': visit_area_df,\n",
    "        'graph_data': data,\n",
    "        'visit_scaler': processor.visit_scaler,\n",
    "        'travel_scaler': processor.travel_scaler,\n",
    "        'device': str(device)\n",
    "    }\n",
    "    \n",
    "    # 6. 파일 저장\n",
    "    print(\"💾 파일 저장 중...\")\n",
    "    \n",
    "    # 모델 저장 (.pt)\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_config': {\n",
    "            'in_channels': visit_area_tensor.shape[1],\n",
    "            'hidden_channels': 128,\n",
    "            'out_channels': 64,\n",
    "            'travel_context_dim': 25,\n",
    "            'num_heads': 4,\n",
    "            'dropout': 0.2\n",
    "        }\n",
    "    }, 'travel_recommendation_model.pt')\n",
    "    \n",
    "    # 데이터 저장 (.pkl)\n",
    "    with open('travel_data.pkl', 'wb') as f:\n",
    "        pickle.dump(save_data, f)\n",
    "    \n",
    "    print(\"✅ 저장 완료!\")\n",
    "    print(\"- travel_recommendation_model.pt: 모델 파라미터\")\n",
    "    print(\"- travel_data.pkl: 전처리된 데이터 및 스케일러\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    save_model_and_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
