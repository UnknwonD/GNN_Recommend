{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv, Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteGNN(nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels=128):\n",
    "        super().__init__()\n",
    "        self.metadata = metadata\n",
    "\n",
    "        # ğŸ’¡ ì‹¤ì œ ì…ë ¥ ì°¨ì›ì— ë§ê²Œ ì¡°ì • (ê³ ì •ëœ ì…ë ¥ ì°¨ì› ì‚¬ìš©)\n",
    "        self.embeddings = nn.ModuleDict({\n",
    "            'user': Linear(17, hidden_channels),\n",
    "            'travel': Linear(21, hidden_channels),\n",
    "            'visit_area': Linear(1, hidden_channels),  # dummy feature\n",
    "        })\n",
    "\n",
    "        # ğŸ’¡ HeteroConv ë ˆì´ì–´ 2ë‹¨\n",
    "        self.gnn1 = HeteroConv({\n",
    "            edge_type: SAGEConv((-1, -1), hidden_channels)\n",
    "            for edge_type in metadata[1]\n",
    "        }, aggr='sum')\n",
    "\n",
    "        self.gnn2 = HeteroConv({\n",
    "            edge_type: SAGEConv((hidden_channels, hidden_channels), hidden_channels)\n",
    "            for edge_type in metadata[1]\n",
    "        }, aggr='sum')\n",
    "\n",
    "        # ğŸ’¡ Link prediction head\n",
    "        self.link_predictor = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # ğŸ” ì„ë² ë”© ì²˜ë¦¬ (None ë°©ì§€)\n",
    "        x_dict = {\n",
    "            node_type: self.embeddings[node_type](x) if x is not None else None\n",
    "            for node_type, x in x_dict.items()\n",
    "        }\n",
    "        \n",
    "        # ğŸ’¬ GNN ë©”ì‹œì§€ ì „ë‹¬\n",
    "        x_dict = self.gnn1(x_dict, edge_index_dict)\n",
    "        x_dict = {k: F.relu(v) for k, v in x_dict.items() if v is not None}\n",
    "        x_dict = self.gnn2(x_dict, edge_index_dict)\n",
    "\n",
    "        return x_dict\n",
    "\n",
    "    def predict_link(self, node_embed, edge_index):\n",
    "        \"\"\"\n",
    "        visit_area ê°„ (i, j) edge ìŒì„ ë°›ì•„ score ì¶œë ¥\n",
    "        \"\"\"\n",
    "        src, dst = edge_index\n",
    "        z_src = node_embed[src]\n",
    "        z_dst = node_embed[dst]\n",
    "        z = torch.cat([z_src, z_dst], dim=-1)\n",
    "        return self.link_predictor(z).squeeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°íƒ€ pkl ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with open('./pickle/user_id_to_index.pkl', 'rb') as f:\n",
    "    user_id_to_index = pickle.load(f)\n",
    "\n",
    "with open('./pickle/travel_id_to_index.pkl', 'rb') as f:\n",
    "    travel_id_to_index = pickle.load(f)\n",
    "\n",
    "with open('./pickle/visit_area_id_to_index.pkl', 'rb') as f:\n",
    "    visit_area_id_to_index = pickle.load(f)\n",
    "\n",
    "with open('./pickle/dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "visit_area_df = pd.read_pickle('./pickle/visit_area_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteGNN(\n",
       "  (embeddings): ModuleDict(\n",
       "    (user): Linear(17, 128, bias=True)\n",
       "    (travel): Linear(21, 128, bias=True)\n",
       "    (visit_area): Linear(1, 128, bias=True)\n",
       "  )\n",
       "  (gnn1): HeteroConv(num_relations=5)\n",
       "  (gnn2): HeteroConv(num_relations=5)\n",
       "  (link_predictor): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = RouteGNN(data.metadata())\n",
    "model.load_state_dict(torch.load('./pickle/routegnn_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì¶”ë¡ ì„ ìœ„í•œ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_route(node_embed, edge_index, edge_scores, start_node=None, max_steps=5):\n",
    "    \"\"\"\n",
    "    visit_area ë…¸ë“œ ì„ë² ë”©, ì—£ì§€ index, scoreê°€ ì£¼ì–´ì¡Œì„ ë•Œ\n",
    "    ê°€ì¥ ë†’ì€ score ê¸°ì¤€ìœ¼ë¡œ ë™ì„ ì„ êµ¬ì„±í•˜ëŠ” greedy ê²½ë¡œ ì¶”ì²œ í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    from collections import defaultdict\n",
    "\n",
    "    # ì—£ì§€ë¥¼ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    scored_edges = list(zip(edge_index[0].tolist(), edge_index[1].tolist(), edge_scores.tolist()))\n",
    "    scored_edges.sort(key=lambda x: -x[2])  # ë†’ì€ ì ìˆ˜ ìˆœ\n",
    "\n",
    "    # ê²½ë¡œ ìƒì„±\n",
    "    visited = set()\n",
    "    route = []\n",
    "\n",
    "    current = start_node if start_node is not None else scored_edges[0][0]\n",
    "    visited.add(current)\n",
    "    route.append(current)\n",
    "\n",
    "    for _ in range(max_steps - 1):\n",
    "        # currentì—ì„œ ì‹œì‘í•˜ëŠ” í›„ë³´ ì¤‘ ì•„ì§ ë°©ë¬¸í•˜ì§€ ì•Šì€ ê³³\n",
    "        candidates = [dst for src, dst, score in scored_edges if src == current and dst not in visited]\n",
    "        if not candidates:\n",
    "            break\n",
    "        next_node = candidates[0]  # greedyí•˜ê²Œ ìµœê³  ì ìˆ˜ ì„ íƒ\n",
    "        visited.add(next_node)\n",
    "        route.append(next_node)\n",
    "        current = next_node\n",
    "\n",
    "    return route  # index í˜•íƒœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_route(model, data, user_input, travel_input, k=5, device='cpu'):\n",
    "    model.eval()\n",
    "    data = data.to(device)\n",
    "    user_input = user_input.to(device)\n",
    "    travel_input = travel_input.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 1. user_inputê³¼ travel_inputì€ ì„ë² ë”© ì „ ìƒíƒœì„ (17ì°¨ì›, 21ì°¨ì›)\n",
    "\n",
    "        # 2. ê¸°ì¡´ raw featureì™€ í•©ì¹˜ê¸° (ê°™ì€ ì°¨ì› ê¸°ì¤€ìœ¼ë¡œ)\n",
    "        x_dict_raw = {\n",
    "            'user': torch.cat([data['user'].x, user_input], dim=0),       # [N+1, 17]\n",
    "            'travel': torch.cat([data['travel'].x, travel_input], dim=0), # [M+1, 21]\n",
    "            'visit_area': data['visit_area'].x                             # [V, 1]\n",
    "        }\n",
    "\n",
    "        # 3. forward: modelì´ ë‚´ë¶€ì—ì„œ ì„ë² ë”© ì²˜ë¦¬í•¨\n",
    "        x_dict = model(x_dict_raw, data.edge_index_dict)\n",
    "\n",
    "        visit_area_embed = x_dict['visit_area']\n",
    "\n",
    "        # 4. ëª¨ë“  visit_area ë…¸ë“œ ìŒì— ëŒ€í•´ link prediction\n",
    "        n = visit_area_embed.size(0)\n",
    "        all_edges = torch.combinations(torch.arange(n, device=device), r=2).t()\n",
    "        edge_scores = model.predict_link(visit_area_embed, all_edges)\n",
    "\n",
    "        # 5. ê²½ë¡œ êµ¬ì„±\n",
    "        route = recommend_route(visit_area_embed, all_edges, edge_scores, max_steps=k)\n",
    "\n",
    "    return route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì € ì •ë³´\n",
    "\n",
    "def get_age_group(birthdate_str):\n",
    "    \"\"\"\n",
    "    'YYYY-MM-DD' í˜•ì‹ì˜ ìƒë…„ì›”ì¼ ë¬¸ìì—´ì„ ë°›ì•„\n",
    "    20, 30, 40 ë“±ì˜ ë‚˜ì´ëŒ€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    birth_year = int(birthdate_str[:4])\n",
    "    current_year = datetime.now().year\n",
    "    age = current_year - birth_year + 1  # í•œêµ­ì‹ ë‚˜ì´\n",
    "    age_group = (age // 10) * 10\n",
    "    return age_group\n",
    "\n",
    "def map_sido(sido:str):\n",
    "    sido_code_map = {\n",
    "        'ì„œìš¸íŠ¹ë³„ì‹œ': '11',\n",
    "        'ë¶€ì‚°ê´‘ì—­ì‹œ': '26',\n",
    "        'ëŒ€êµ¬ê´‘ì—­ì‹œ': '27',\n",
    "        'ì¸ì²œê´‘ì—­ì‹œ': '28',\n",
    "        'ê´‘ì£¼ê´‘ì—­ì‹œ': '29',\n",
    "        'ëŒ€ì „ê´‘ì—­ì‹œ': '30',\n",
    "        'ìš¸ì‚°ê´‘ì—­ì‹œ': '31',\n",
    "        'ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ': '36',\n",
    "        'ê²½ê¸°ë„': '41',\n",
    "        'ê°•ì›ë„': '42',\n",
    "        'ì¶©ì²­ë¶ë„': '43',\n",
    "        'ì¶©ì²­ë‚¨ë„': '44',\n",
    "        'ì „ë¼ë¶ë„': '45',\n",
    "        'ì „ë¼ë‚¨ë„': '46',\n",
    "        'ê²½ìƒë¶ë„': '47',\n",
    "        'ê²½ìƒë‚¨ë„': '48',\n",
    "        'ì œì£¼íŠ¹ë³„ìì¹˜ë„': '50'\n",
    "    }\n",
    "\n",
    "    return int(sido_code_map[sido])\n",
    "\n",
    "def process_user_input(user_info:dict):\n",
    "    user_feature_cols = [\n",
    "    'GENDER', 'TRAVEL_TERM', 'TRAVEL_NUM',\n",
    "    'TRAVEL_LIKE_SIDO_1', 'TRAVEL_LIKE_SIDO_2', 'TRAVEL_LIKE_SIDO_3',\n",
    "    'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "    'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "    'TRAVEL_MOTIVE_1', 'TRAVEL_MOTIVE_2',\n",
    "    'AGE_GRP'\n",
    "    ]\n",
    "    \n",
    "    # 1. ë‚˜ì‡ëŒ€ ê³„ì‚°\n",
    "    user_info['AGE_GRP'] = get_age_group(user_info['BIRTHDATE'])\n",
    "    \n",
    "    # 2. ì‹œë„ ë³€í™˜\n",
    "    for i in range(1, 4):\n",
    "        user_info[f\"TRAVEL_LIKE_SIDO_{i}\"] = map_sido(user_info[f\"TRAVEL_LIKE_SIDO_{i}\"])\n",
    "    \n",
    "    # 3. ì»¬ëŸ¼ í•„í„°ë§ (ìˆœì„œì— ë§ê²Œ)\n",
    "    user_info = {k: int(user_info[k]) for k in user_feature_cols}\n",
    "    \n",
    "    return pd.DataFrame([user_info]).fillna(0).astype(np.float32).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬í–‰ ì •ë³´\n",
    "def process_travel_input(travel_info:dict):\n",
    "    from datetime import datetime\n",
    "    travel_feature_cols = [\n",
    "        'TOTAL_COST_BINNED_ENCODED',\n",
    "        'WITH_PET',\n",
    "        'MONTH',\n",
    "        'DURATION',\n",
    "        'MVMN_ê¸°íƒ€',\n",
    "        'MVMN_ëŒ€ì¤‘êµí†µ',\n",
    "        'MVMN_ìê°€ìš©',\n",
    "        'TRAVEL_PURPOSE_1',\n",
    "        'TRAVEL_PURPOSE_2',\n",
    "        'TRAVEL_PURPOSE_3',\n",
    "        'TRAVEL_PURPOSE_4',\n",
    "        'TRAVEL_PURPOSE_5',\n",
    "        'TRAVEL_PURPOSE_6',\n",
    "        'TRAVEL_PURPOSE_7',\n",
    "        'TRAVEL_PURPOSE_8',\n",
    "        'TRAVEL_PURPOSE_9',\n",
    "        'WHOWITH_2ì¸ì—¬í–‰',\n",
    "        'WHOWITH_ê°€ì¡±ì—¬í–‰',\n",
    "        'WHOWITH_ê¸°íƒ€',\n",
    "        'WHOWITH_ë‹¨ë…ì—¬í–‰',\n",
    "        'WHOWITH_ì¹œêµ¬/ì§€ì¸ ì—¬í–‰']\n",
    "    \n",
    "    \n",
    "    # mission_ENCì— 0 = ë°˜ë ¤ë™ë¬¼ ë™ë°˜ (WITH_PET)\n",
    "    travel_info['mission_ENC'] = travel_info['mission_ENC'].strip().split(',')\n",
    "    if '0' in travel_info['mission_ENC']:\n",
    "        travel_info['WITH_PET'] = 1\n",
    "    else:\n",
    "        travel_info['WITH_PET'] = 0\n",
    "        \n",
    "    # TRAVEL_PURPOSE_1 ~~ TRAVEL_PURPOSE_9 (0ìœ¼ë¡œ ë“¤ì–´ì˜¨ ì…ë ¥ì€ ì œê±°í•´ì¤˜ì•¼ë¨) \n",
    "    for i in range(1,10):\n",
    "        if str(i) in travel_info['mission_ENC']:\n",
    "            travel_info[f'TRAVEL_PURPOSE_{i}'] = 1\n",
    "        else:\n",
    "            travel_info[f'TRAVEL_PURPOSE_{i}'] = 0\n",
    "        \n",
    "    # MONTH\n",
    "    dates = travel_info['date_range'].split(' - ')\n",
    "    travel_info['start_date'] = datetime.strptime(dates[0].strip(), \"%Y-%m-%d\")\n",
    "    travel_info['end_date'] = datetime.strptime(dates[1].strip(), \"%Y-%m-%d\")\n",
    "    \n",
    "    travel_info['MONTH'] = travel_info['end_date'].month\n",
    "    \n",
    "    # DURATION\n",
    "    travel_info['DURATION'] = (travel_info['end_date'] - travel_info['start_date']).days\n",
    "    \n",
    "    # MNVM_ê¸°íƒ€, MVMN_ëŒ€ì¤‘êµí†µ, MVMN_ìê°€ìš©\n",
    "    for m in ['ìê°€ìš©', 'ëŒ€ì¤‘êµí†µ', 'ê¸°íƒ€']:\n",
    "        travel_info[f\"MVMN_{m}\"] = False\n",
    "    \n",
    "    if travel_info['MVMN_NM_ENC'] == '1':\n",
    "        travel_info['MVMN_ìê°€ìš©'] = True\n",
    "    elif travel_info['MVMN_NM_ENC'] == '2':\n",
    "        travel_info['MVMN_ëŒ€ì¤‘êµí†µ'] = True\n",
    "    else:\n",
    "        travel_info['MVMN_ê¸°íƒ€'] = True\n",
    "    \n",
    "    # WHOWITHëŠ” 1ë¶€í„° 5ê¹Œì§€ ìˆ«ìë¡œ ë“¤ì–´ì˜´ -> ì›í•« ì¸ì½”ë”©ìœ¼ë¡œ ìˆ˜ì •í•  ê²ƒ\n",
    "    # dictì— ë“¤ì–´ì˜¤ëŠ” ìˆ«ì ì˜ë¯¸: WHOWITH_ë‹¨ë…ì—¬í–‰, WHOWITH_2ì¸ì—¬í–‰, WHOWITH_ê°€ì¡±ì—¬í–‰, WHOWITH_ì¹œêµ¬/ì§€ì¸ì—¬í–‰, WHOWITH_ê¸°íƒ€\n",
    "    whowith_onehot = [0] * 5\n",
    "    idx = int(travel_info['whowith_ENC']) - 1\n",
    "    if 0 <= idx < 5:\n",
    "        whowith_onehot[idx] = 1\n",
    "    \n",
    "    travel_info.update({\n",
    "    'WHOWITH_ë‹¨ë…ì—¬í–‰': whowith_onehot[0],\n",
    "    'WHOWITH_2ì¸ì—¬í–‰': whowith_onehot[1],\n",
    "    'WHOWITH_ê°€ì¡±ì—¬í–‰': whowith_onehot[2],\n",
    "    'WHOWITH_ì¹œêµ¬/ì§€ì¸ ì—¬í–‰': whowith_onehot[3],\n",
    "    'WHOWITH_ê¸°íƒ€': whowith_onehot[4],\n",
    "    })\n",
    "    \n",
    "    # TOTAL_COST_BINNED_ENCODED\n",
    "    travel_info['TOTAL_COST_BINNED_ENCODED'] = travel_info['TOTAL_COST'][-1]\n",
    "    \n",
    "    # ì»¬ëŸ¼ í•„í„°ë§ (ìˆœì„œì— ë§ê²Œ)\n",
    "    travel_info = {k: int(travel_info[k]) for k in travel_feature_cols}\n",
    "    \n",
    "    return pd.DataFrame([travel_info]).fillna(0).astype(np.float32).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_location_by_distance(route_ids, visit_area_df):\n",
    "    selected_names = []\n",
    "\n",
    "    for idx, vid in enumerate(route_ids):\n",
    "        candidates = visit_area_df[visit_area_df['VISIT_AREA_ID'] == vid]\n",
    "\n",
    "        # í›„ë³´ê°€ í•˜ë‚˜ì¼ ê²½ìš° ë°”ë¡œ ì„ íƒ\n",
    "        if len(candidates) == 1:\n",
    "            selected_names.append(candidates.iloc[0]['VISIT_AREA_NM'])\n",
    "            continue\n",
    "\n",
    "        # ì´ì „/ë‹¤ìŒ ìœ„ì¹˜ ì¢Œí‘œ í™•ë³´\n",
    "        prev_coord = None\n",
    "        next_coord = None\n",
    "\n",
    "        if idx > 0:\n",
    "            prev_id = route_ids[idx - 1]\n",
    "            prev_row = visit_area_df[visit_area_df['VISIT_AREA_ID'] == prev_id]\n",
    "            if not prev_row.empty:\n",
    "                prev_coord = (prev_row.iloc[0]['X_COORD'], prev_row.iloc[0]['Y_COORD'])\n",
    "\n",
    "        if idx < len(route_ids) - 1:\n",
    "            next_id = route_ids[idx + 1]\n",
    "            next_row = visit_area_df[visit_area_df['VISIT_AREA_ID'] == next_id]\n",
    "            if not next_row.empty:\n",
    "                next_coord = (next_row.iloc[0]['X_COORD'], next_row.iloc[0]['Y_COORD'])\n",
    "\n",
    "        # ê±°ë¦¬ ê³„ì‚° í•¨ìˆ˜\n",
    "        def total_distance(row):\n",
    "            x, y = row['X_COORD'], row['Y_COORD']\n",
    "            dist = 0\n",
    "            if prev_coord:\n",
    "                dist += np.linalg.norm(np.array([x, y]) - np.array(prev_coord))\n",
    "            if next_coord:\n",
    "                dist += np.linalg.norm(np.array([x, y]) - np.array(next_coord))\n",
    "            return dist\n",
    "\n",
    "        # ìµœë‹¨ ê±°ë¦¬ í›„ë³´ ì„ íƒ\n",
    "        best_row = candidates.loc[candidates.apply(total_distance, axis=1).idxmin()]\n",
    "        selected_names.append(best_row['VISIT_AREA_NM'])\n",
    "\n",
    "    return selected_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì…ë ¥ ë° í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 17)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  1.,  1., 26., 46., 44.,  4.,  4.,  1.,  5.,  2.,  4.,  3.,\n",
       "         2.,  7.,  7., 20.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_info = {'USER_ID': 'admin', 'PASSWORD': 'admin', 'CONFIRM_PASSWORD': 'admin', 'NAME': 'ìœ ìƒë²”', 'BIRTHDATE': '1999-08-10', 'GENDER': '2', 'EDU_NM': '6', 'EDU_FNSH_SE': '2', 'MARR_STTS': '1', 'JOB_NM': '1', 'INCOME': '100', 'HOUSE_INCOME': '10000', 'TRAVEL_TERM': '1', 'TRAVEL_LIKE_SIDO_1': 'ë¶€ì‚°ê´‘ì—­ì‹œ', 'TRAVEL_LIKE_SIDO_2': 'ì „ë¼ë‚¨ë„', 'TRAVEL_LIKE_SIDO_3': 'ì¶©ì²­ë‚¨ë„', 'TRAVEL_STYL_1': 4, 'TRAVEL_STYL_2': 4, 'TRAVEL_STYL_3': 1, 'TRAVEL_STYL_4': 5, 'TRAVEL_STYL_5': 2, 'TRAVEL_STYL_6': 4, 'TRAVEL_STYL_7': 3, 'TRAVEL_STYL_8': 2, 'TRAVEL_MOTIVE_1': '7', 'TRAVEL_MOTIVE_2': '7', 'FAMILY_MEMB': '1', 'TRAVEL_NUM': '1', 'TRAVEL_COMPANIONS_NUM': '1'}\n",
    "\n",
    "\n",
    "test_user_tensor = process_user_input(temp_info)\n",
    "\n",
    "print(test_user_tensor.shape)\n",
    "test_user_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4., 0., 9., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_travel = {'mission_ENC': '1,2,3,7,9', 'date_range': '2025-09-28 - 2025-09-29', 'start_date': '', 'end_date': '', 'TOTAL_COST': '4', 'MVMN_NM_ENC': '1', 'whowith_ENC': '1', 'mission_type': 'normal'}\n",
    "\n",
    "\n",
    "test_travel_tensor = process_travel_input(test_travel)\n",
    "\n",
    "print(test_travel_tensor.shape)\n",
    "test_travel_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 17]), torch.Size([1, 21]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = torch.tensor(test_user_tensor, dtype=torch.float)  # 17ì°¨ì›\n",
    "travel_input = torch.tensor(test_travel_tensor, dtype=torch.float)  # 21ì°¨ì›\n",
    "\n",
    "user_input.shape, travel_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_indices = infer_route(model, data, user_input, travel_input, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ ë™ì„ : [2307300011, 2307300012, 2308040013, 2308160007, 2308290010, 2309110002, 2309110005, 2309110006, 2309110007, 2309110008]\n"
     ]
    }
   ],
   "source": [
    "# visit_area_idë¡œ ì—­ë§¤í•‘\n",
    "index_to_id = {v: k for k, v in visit_area_id_to_index.items()}\n",
    "route_ids = [index_to_id[idx] for idx in route_indices]\n",
    "print(\"ì¶”ì²œ ë™ì„ :\", route_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2307300011 : ì„œìš¸ì›”ë“œì»µê²½ê¸°ì¥\n",
      "2307300012 : ë‚˜ì¸ íŠ¸ë¦¬ í”„ë¦¬ë¯¸ì–´ ë¡œì¹´ìš°ìŠ¤ í˜¸í…” ì„œìš¸ ìš©ì‚°\n",
      "2308040013 : ì²­íŒŒ ì±…ê°€ë„\n",
      "2308160007 : ë¹„í‹€ìŠ¤\n",
      "2308290010 : ìƒê³„ì£¼ê³µ 1ë‹¨ì§€ ì•„íŒŒíŠ¸\n",
      "2309110002 : AKí”Œë¼ì í™ëŒ€\n",
      "2309110005 : AKí”Œë¼ì í™ëŒ€\n",
      "2309110006 : ìˆ˜ë‚˜ ì½” 3í˜¸ì \n",
      "2309110007 : í› ê¶ˆ ë‚˜ë¼ í™ëŒ€ì \n",
      "2309110008 : ë‰´ ì½”ì¸ ì‹±ì–´ ë…¸ë˜ì—°ìŠµì¥\n"
     ]
    }
   ],
   "source": [
    "names = select_best_location_by_distance(route_ids, visit_area_df)\n",
    "\n",
    "for vid, name in zip(route_ids, names):\n",
    "    print(vid, \":\", name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
