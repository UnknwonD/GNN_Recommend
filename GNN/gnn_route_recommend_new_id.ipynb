{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 파일 경로\n",
    "move_path = \"../data/VL_csv/move_with_new_id_final.csv\"\n",
    "travel_path = \"tn_travel_processed.csv\"\n",
    "visit_area_path = \"../data/VL_csv/visit_area_with_new_id_final.csv\"\n",
    "\n",
    "# 데이터 로딩\n",
    "move_df = pd.read_csv(move_path)\n",
    "travel_df = pd.read_csv(travel_path)\n",
    "visit_area_df = pd.read_csv(visit_area_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GNN 학습용 전처리 데이터 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 2️⃣ visit_area feature 생성\n",
    "visit_area_df['X_COORD'] = visit_area_df['X_COORD'].fillna(visit_area_df['X_COORD'].mean())\n",
    "visit_area_df['Y_COORD'] = visit_area_df['Y_COORD'].fillna(visit_area_df['Y_COORD'].mean())\n",
    "visit_area_df['VISIT_CHC_REASON_CD'] = visit_area_df['VISIT_CHC_REASON_CD'].fillna(0)\n",
    "for col in ['DGSTFN', 'REVISIT_INTENTION', 'RCMDTN_INTENTION']:\n",
    "    visit_area_df[col] = visit_area_df[col].fillna(3)\n",
    "\n",
    "features = visit_area_df[['X_COORD', 'Y_COORD']].copy()\n",
    "type_onehot = pd.get_dummies(visit_area_df['VISIT_AREA_TYPE_CD'], prefix='type')\n",
    "reason_onehot = pd.get_dummies(visit_area_df['VISIT_CHC_REASON_CD'], prefix='reason')\n",
    "visit_area_df['DGSTFN_norm'] = (visit_area_df['DGSTFN'] - 1) / 4.0\n",
    "visit_area_df['REVISIT_norm'] = (visit_area_df['REVISIT_INTENTION'] - 1) / 4.0\n",
    "visit_area_df['RCMDTN_norm'] = (visit_area_df['RCMDTN_INTENTION'] - 1) / 4.0\n",
    "features = pd.concat([features, type_onehot, reason_onehot,\n",
    "                      visit_area_df[['DGSTFN_norm', 'REVISIT_norm', 'RCMDTN_norm']]], axis=1)\n",
    "scaler = StandardScaler()\n",
    "visit_area_tensor = scaler.fit_transform(features.to_numpy(dtype=np.float32))\n",
    "\n",
    "# 3️⃣ edge_index, edge_attr 생성\n",
    "edges = []\n",
    "for travel_id, group in move_df.groupby(\"TRAVEL_ID\"):\n",
    "    group = group.sort_values(\"TRIP_ID\").reset_index(drop=True)\n",
    "    for i in range(1, len(group)):\n",
    "        from_id = group.loc[i-1, \"END_NEW_ID\"]\n",
    "        to_id = group.loc[i, \"END_NEW_ID\"]\n",
    "        duration = group.loc[i, \"DURATION_MINUTES\"] if \"DURATION_MINUTES\" in group.columns else 0\n",
    "        transport = group.loc[i, \"MVMN_CD_1\"]\n",
    "        if pd.notna(from_id) and pd.notna(to_id):\n",
    "            edges.append([int(from_id), int(to_id), duration, transport])\n",
    "\n",
    "edges_df = pd.DataFrame(edges, columns=[\"FROM_ID\", \"TO_ID\", \"DURATION_MINUTES\", \"MVMN_CD_1\"])\n",
    "edge_index = torch.tensor(edges_df[[\"FROM_ID\", \"TO_ID\"]].to_numpy().T, dtype=torch.long)\n",
    "edge_attr = edges_df[[\"DURATION_MINUTES\"]].fillna(0).astype(np.float32).to_numpy()\n",
    "edges_df[\"MVMN_TYPE\"] = edges_df[\"MVMN_CD_1\"].apply(lambda code: \"drive\" if code in [1,2,3] else \"public\" if code in [4,5,6,7,8,9,10,11,12,13,50] else \"other\")\n",
    "edges_df[\"is_drive\"] = (edges_df[\"MVMN_TYPE\"] == \"drive\").astype(int)\n",
    "edges_df[\"is_public\"] = (edges_df[\"MVMN_TYPE\"] == \"public\").astype(int)\n",
    "edges_df[\"is_other\"] = (edges_df[\"MVMN_TYPE\"] == \"other\").astype(int)\n",
    "edge_attr = torch.tensor(np.hstack([edge_attr, edges_df[[\"is_drive\", \"is_public\", \"is_other\"]].to_numpy()]), dtype=torch.float32)\n",
    "\n",
    "# 4️⃣ travel_tensor 생성\n",
    "excluded_cols = ['Unnamed: 0', 'TRAVEL_ID', 'TRAVELER_ID']\n",
    "travel_feature_cols = [col for col in travel_df.columns if col not in excluded_cols]\n",
    "travel_tensor = travel_df[travel_feature_cols].fillna(0).astype(np.float32).to_numpy()\n",
    "\n",
    "# 5️⃣ 최종 numpy 저장\n",
    "np.save(\"../data/VL_csv/visit_area_tensor.npy\", visit_area_tensor)\n",
    "np.save(\"../data/VL_csv/edge_index.npy\", edge_index.numpy())\n",
    "np.save(\"../data/VL_csv/edge_attr.npy\", edge_attr.numpy())\n",
    "np.save(\"../data/VL_csv/travel_tensor.npy\", travel_tensor)\n",
    "\n",
    "print(\"✅ GNN 학습용 전처리 데이터 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "# 1️⃣ numpy로부터 데이터 로드\n",
    "visit_area_tensor = np.load(\"../data/VL_csv/visit_area_tensor.npy\")\n",
    "edge_index = np.load(\"../data/VL_csv/edge_index.npy\")\n",
    "edge_attr = np.load(\"../data/VL_csv/edge_attr.npy\")\n",
    "travel_tensor = np.load(\"../data/VL_csv/travel_tensor.npy\")\n",
    "\n",
    "# 2️⃣ HeteroData 생성\n",
    "data = HeteroData()\n",
    "data['visit_area'].x = torch.tensor(visit_area_tensor, dtype=torch.float32)\n",
    "data['visit_area', 'moved_to', 'visit_area'].edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "data['visit_area', 'moved_to', 'visit_area'].edge_attr = torch.tensor(edge_attr, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  visit_area={ x=[21384, 34] },\n",
       "  (visit_area, moved_to, visit_area)={\n",
       "    edge_index=[2, 16232],\n",
       "    edge_attr=[16232, 4],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class TravelGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.lin_out = nn.Linear(out_channels + travel_tensor.shape[1], out_channels)  # travel context concat\n",
    "\n",
    "    def forward(self, data, travel_context):\n",
    "        x, edge_index, edge_attr = data['visit_area'].x, data['visit_area', 'moved_to', 'visit_area'].edge_index, data['visit_area', 'moved_to', 'visit_area'].edge_attr\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        # travel context를 모든 visit_area에 concat (broadcast)\n",
    "        travel_context_expanded = travel_context.expand(x.size(0), -1)\n",
    "        x = torch.cat([x, travel_context_expanded], dim=1)\n",
    "        return self.lin_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.6666\n",
      "Epoch 100, Loss: 0.3558\n",
      "Epoch 150, Loss: 0.1726\n",
      "Epoch 200, Loss: 0.0781\n",
      "Epoch 250, Loss: 0.0393\n",
      "Epoch 300, Loss: 0.0267\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 모델 선언 부분\n",
    "model = TravelGNN(in_channels=visit_area_tensor.shape[1], hidden_channels=64, out_channels=34).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()  # 예: feature reconstruction\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "# 예시: travel_tensor 중 첫 여행정보로 학습\n",
    "travel_context_tensor = torch.tensor(travel_tensor[0:1], dtype=torch.float32).to(device)\n",
    "target = data['visit_area'].x  # 예: 방문지 feature 자체 복원\n",
    "\n",
    "for epoch in range(1, 301):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data, travel_context_tensor)\n",
    "    loss = criterion(out, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여행 정보\n",
    "def process_travel_input(travel_info:dict):\n",
    "    from datetime import datetime\n",
    "    travel_feature_cols = [\n",
    "        'TOTAL_COST_BINNED_ENCODED',\n",
    "        'WITH_PET',\n",
    "        'MONTH',\n",
    "        'DURATION',\n",
    "        'MVMN_기타',\n",
    "        'MVMN_대중교통',\n",
    "        'MVMN_자가용',\n",
    "        'TRAVEL_PURPOSE_1',\n",
    "        'TRAVEL_PURPOSE_2',\n",
    "        'TRAVEL_PURPOSE_3',\n",
    "        'TRAVEL_PURPOSE_4',\n",
    "        'TRAVEL_PURPOSE_5',\n",
    "        'TRAVEL_PURPOSE_6',\n",
    "        'TRAVEL_PURPOSE_7',\n",
    "        'TRAVEL_PURPOSE_8',\n",
    "        'TRAVEL_PURPOSE_9',\n",
    "        'WHOWITH_2인여행',\n",
    "        'WHOWITH_가족여행',\n",
    "        'WHOWITH_기타',\n",
    "        'WHOWITH_단독여행',\n",
    "        'WHOWITH_친구/지인 여행']\n",
    "    \n",
    "    \n",
    "    # mission_ENC에 0 = 반려동물 동반 (WITH_PET)\n",
    "    travel_info['mission_ENC'] = travel_info['mission_ENC'].strip().split(',')\n",
    "    if '0' in travel_info['mission_ENC']:\n",
    "        travel_info['WITH_PET'] = 1\n",
    "    else:\n",
    "        travel_info['WITH_PET'] = 0\n",
    "        \n",
    "    # TRAVEL_PURPOSE_1 ~~ TRAVEL_PURPOSE_9 (0으로 들어온 입력은 제거해줘야됨) \n",
    "    for i in range(1,10):\n",
    "        if str(i) in travel_info['mission_ENC']:\n",
    "            travel_info[f'TRAVEL_PURPOSE_{i}'] = 1\n",
    "        else:\n",
    "            travel_info[f'TRAVEL_PURPOSE_{i}'] = 0\n",
    "        \n",
    "    # MONTH\n",
    "    dates = travel_info['date_range'].split(' - ')\n",
    "    travel_info['start_date'] = datetime.strptime(dates[0].strip(), \"%Y-%m-%d\")\n",
    "    travel_info['end_date'] = datetime.strptime(dates[1].strip(), \"%Y-%m-%d\")\n",
    "    \n",
    "    travel_info['MONTH'] = travel_info['end_date'].month\n",
    "    \n",
    "    # DURATION\n",
    "    travel_info['DURATION'] = (travel_info['end_date'] - travel_info['start_date']).days\n",
    "    \n",
    "    # MNVM_기타, MVMN_대중교통, MVMN_자가용\n",
    "    for m in ['자가용', '대중교통', '기타']:\n",
    "        travel_info[f\"MVMN_{m}\"] = False\n",
    "    \n",
    "    if travel_info['MVMN_NM_ENC'] == '1':\n",
    "        travel_info['MVMN_자가용'] = True\n",
    "    elif travel_info['MVMN_NM_ENC'] == '2':\n",
    "        travel_info['MVMN_대중교통'] = True\n",
    "    else:\n",
    "        travel_info['MVMN_기타'] = True\n",
    "    \n",
    "    # WHOWITH는 1부터 5까지 숫자로 들어옴 -> 원핫 인코딩으로 수정할 것\n",
    "    # dict에 들어오는 숫자 의미: WHOWITH_단독여행, WHOWITH_2인여행, WHOWITH_가족여행, WHOWITH_친구/지인여행, WHOWITH_기타\n",
    "    whowith_onehot = [0] * 5\n",
    "    idx = int(travel_info['whowith_ENC']) - 1\n",
    "    if 0 <= idx < 5:\n",
    "        whowith_onehot[idx] = 1\n",
    "    \n",
    "    travel_info.update({\n",
    "    'WHOWITH_단독여행': whowith_onehot[0],\n",
    "    'WHOWITH_2인여행': whowith_onehot[1],\n",
    "    'WHOWITH_가족여행': whowith_onehot[2],\n",
    "    'WHOWITH_친구/지인 여행': whowith_onehot[3],\n",
    "    'WHOWITH_기타': whowith_onehot[4],\n",
    "    })\n",
    "    \n",
    "    # TOTAL_COST_BINNED_ENCODED\n",
    "    travel_info['TOTAL_COST_BINNED_ENCODED'] = travel_info['TOTAL_COST'][-1]\n",
    "    \n",
    "    # 컬럼 필터링 (순서에 맞게)\n",
    "    travel_info = {k: int(travel_info[k]) for k in travel_feature_cols}\n",
    "    \n",
    "    return pd.DataFrame([travel_info]).fillna(0).astype(np.float32).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 초기 추천 top-10 (ID | 명칭):\n",
      "1. 6212 | 로컬 스티치 홍대 2호\n",
      "2. 4958 | 가톨릭대학교 성심교정\n",
      "3. 1755 | 젠트리\n",
      "4. 4270 | 서울 가락 초등학교\n",
      "5. 1755 | 젠트리\n",
      "6. 9177 | KDB산업은행 대전지점\n",
      "7. 344 | 송도센트럴파크\n",
      "8. 7531 | 킨텍스 제1전시장\n",
      "9. 9181 | 인천 중구청 본관\n",
      "10. 9181 | 인천 중구청 본관\n",
      "\n",
      "🚫 랜덤으로 선택된 싫어요 장소 ID: [9181, 6212, 9177]\n",
      "🌀 싫어요 장소 9181 (middle) → 대체 추천 9181 | 인천 중구청 본관\n",
      "🌀 싫어요 장소 6212 (start) → 대체 추천 1755 | 젠트리\n",
      "🌀 싫어요 장소 9177 (middle) → 대체 추천 1755 | 젠트리\n",
      "\n",
      "✨ 싫어요 반영 후 추천 top-10 (ID | 명칭):\n",
      "1. 4958 | 가톨릭대학교 성심교정\n",
      "2. 1755 | 젠트리\n",
      "3. 4270 | 서울 가락 초등학교\n",
      "4. 1755 | 젠트리\n",
      "5. 344 | 송도센트럴파크\n",
      "6. 7531 | 킨텍스 제1전시장\n",
      "7. 2432 | 난지한강공원\n",
      "8. 777 | 캐리비안베이\n",
      "9. 2176 | 여의도 물빛무대\n",
      "10. 1515 | 동국대학교 서울캠퍼스\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# 여행 정보 전처리\n",
    "test_travel = {\n",
    "    'mission_ENC': '0,1',\n",
    "    'date_range': '2025-09-28 - 2025-10-31',\n",
    "    'start_date': '',\n",
    "    'end_date': '',\n",
    "    'TOTAL_COST': '1',\n",
    "    'MVMN_NM_ENC': '2',\n",
    "    'whowith_ENC': '1',\n",
    "    'mission_type': 'normal'\n",
    "}\n",
    "test_travel_tensor = process_travel_input(test_travel)\n",
    "test_travel_tensor = torch.tensor(test_travel_tensor, dtype=torch.float32).to(device)\n",
    "\n",
    "# GNN 추론\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_visit_area_embeddings = model(data, test_travel_tensor)  # (N, 34)\n",
    "\n",
    "# 추천 top-10\n",
    "scores = predicted_visit_area_embeddings.norm(dim=1)\n",
    "topk_indices = torch.topk(scores, k=10).indices\n",
    "topk_recommend = visit_area_df.loc[topk_indices.tolist(), [\"NEW_VISIT_AREA_ID\", \"VISIT_AREA_NM\"]]\n",
    "topk_recommend_list = topk_recommend.values.tolist()\n",
    "\n",
    "print(\"✅ 초기 추천 top-10 (ID | 명칭):\")\n",
    "for idx, (area_id, area_nm) in enumerate(topk_recommend_list, 1):\n",
    "    print(f\"{idx}. {area_id} | {area_nm}\")\n",
    "\n",
    "# 랜덤으로 싫어요 표시\n",
    "num_dislike = 3\n",
    "disliked_area_ids = random.sample([area_id for area_id, _ in topk_recommend_list], k=num_dislike)\n",
    "print(\"\\n🚫 랜덤으로 선택된 싫어요 장소 ID:\", disliked_area_ids)\n",
    "\n",
    "# start/middle/end 자동 결정 & 좌표 기반 best index 찾기\n",
    "def find_best_replacement(disliked_rows, prev_coords, next_coords, mode):\n",
    "    best_idx = None\n",
    "    min_distance = float('inf')\n",
    "    \n",
    "    for idx, row in disliked_rows.iterrows():\n",
    "        x = row[\"X_COORD\"]\n",
    "        y = row[\"Y_COORD\"]\n",
    "        \n",
    "        if mode == \"start\":\n",
    "            dist_next = np.sqrt((x - next_coords[0])**2 + (y - next_coords[1])**2)\n",
    "            total_dist = dist_next\n",
    "        elif mode == \"end\":\n",
    "            dist_prev = np.sqrt((x - prev_coords[0])**2 + (y - prev_coords[1])**2)\n",
    "            total_dist = dist_prev\n",
    "        else:  # middle\n",
    "            dist_prev = np.sqrt((x - prev_coords[0])**2 + (y - prev_coords[1])**2)\n",
    "            dist_next = np.sqrt((x - next_coords[0])**2 + (y - next_coords[1])**2)\n",
    "            total_dist = dist_prev + dist_next\n",
    "        \n",
    "        if total_dist < min_distance:\n",
    "            min_distance = total_dist\n",
    "            best_idx = idx\n",
    "    return best_idx\n",
    "\n",
    "for disliked_id in disliked_area_ids:\n",
    "    disliked_rows = visit_area_df[visit_area_df[\"NEW_VISIT_AREA_ID\"] == disliked_id]\n",
    "    dislike_loc = [area_id for area_id, _ in topk_recommend_list].index(disliked_id)\n",
    "    \n",
    "    mode = \"start\" if dislike_loc == 0 else \"end\" if dislike_loc == len(topk_indices) - 1 else \"middle\"\n",
    "    \n",
    "    if mode == 'start':        \n",
    "        prev_coords = disliked_rows[['X_COORD', 'Y_COORD']].values.tolist()[0]\n",
    "        next_id = topk_recommend_list[dislike_loc+1][0]\n",
    "        next_coords = visit_area_df[visit_area_df[\"NEW_VISIT_AREA_ID\"] == next_id][['X_COORD', 'Y_COORD']].values.tolist()[0]\n",
    "    elif mode == 'end':\n",
    "        prev_id = topk_recommend_list[dislike_loc-1][0]\n",
    "        prev_coords = visit_area_df[visit_area_df[\"NEW_VISIT_AREA_ID\"] == prev_id][['X_COORD', 'Y_COORD']].values.tolist()[0]\n",
    "        next_coords = disliked_rows[['X_COORD', 'Y_COORD']].values.tolist()[0]\n",
    "    else:\n",
    "        prev_id = topk_recommend_list[dislike_loc-1][0]\n",
    "        next_id = topk_recommend_list[dislike_loc+1][0]\n",
    "        prev_coords = visit_area_df[visit_area_df[\"NEW_VISIT_AREA_ID\"] == prev_id][['X_COORD', 'Y_COORD']].values.tolist()[0]\n",
    "        next_coords = visit_area_df[visit_area_df[\"NEW_VISIT_AREA_ID\"] == next_id][['X_COORD', 'Y_COORD']].values.tolist()[0]\n",
    "\n",
    "    best_idx = find_best_replacement(disliked_rows, prev_coords, next_coords, mode)\n",
    "    \n",
    "    disliked_emb = predicted_visit_area_embeddings[best_idx]\n",
    "    distances = torch.norm(predicted_visit_area_embeddings - disliked_emb, dim=1)\n",
    "    distances[best_idx] = 1e9  # 자기 자신 제외\n",
    "    \n",
    "    replacement_idx = torch.argmin(distances).item()\n",
    "    replacement_id = visit_area_df.iloc[replacement_idx][\"NEW_VISIT_AREA_ID\"]\n",
    "    replacement_nm = visit_area_df.iloc[replacement_idx][\"VISIT_AREA_NM\"]\n",
    "    \n",
    "    print(f\"🌀 싫어요 장소 {disliked_id} ({mode}) → 대체 추천 {replacement_id} | {replacement_nm}\")\n",
    "\n",
    "# 싫어요 반영 후 top-10 추천\n",
    "disliked_indices = visit_area_df[visit_area_df[\"NEW_VISIT_AREA_ID\"].isin(disliked_area_ids)].index.tolist()\n",
    "scores_post = scores.clone()\n",
    "scores_post[disliked_indices] = -1e9  # 제외\n",
    "\n",
    "topk_indices_post = torch.topk(scores_post, k=10).indices\n",
    "topk_recommend_post = visit_area_df.loc[topk_indices_post.tolist(), [\"NEW_VISIT_AREA_ID\", \"VISIT_AREA_NM\"]]\n",
    "topk_recommend_post_list = topk_recommend_post.values.tolist()\n",
    "\n",
    "print(\"\\n✨ 싫어요 반영 후 추천 top-10 (ID | 명칭):\")\n",
    "for idx, (area_id, area_nm) in enumerate(topk_recommend_post_list, 1):\n",
    "    print(f\"{idx}. {area_id} | {area_nm}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
