{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ—“ï¸ ì¶”ì²œ ì¼ì •:\n",
      "Day 1: ['ì œì£¼ êµ­ì œê³µí•­', 'ì„œê°€ ì•¤ ì¿¡ KTX ì„œìš¸ ì—­ì‚¬ì ', 'ì‚¼ì§„ ì–´ë¬µ ë¶€ì‚°ì—­ ê´‘ì¥ì ']\n",
      "Day 2: ['í˜„ëŒ€ í”„ë¦¬ë¯¸ì—„ ì•„ìš¸ë › ìŠ¤í˜ì´ìŠ¤ ì›', 'ì½”ì—‘ìŠ¤', 'ì¥ì¸ ë‹­ê°ˆë¹„ ê°•ë‚¨ì ', 'ì„œìš¸ëœë“œ', 'ì™•ìƒê°€ ì¹¼êµ­ìˆ˜', 'ì—°ì²œ í˜¸ë¡œ ê³ ë£¨', 'í™”ê°œì‚° ì†ì¹¼êµ­ìˆ˜', 'íˆ¬ì¸í”Œë ˆì´ìŠ¤ í™”ì„±ì‚¬ ê°•ì ', 'ì•„ì‚°ì—­', 'ê³ í–¥ì‹ë‹¹', 'ë¡¯ë°ë¦¬ì•„ ì² ì› ì™€ìˆ˜ì ', 'ê²½í¬ëŒ€']\n",
      "âœ… í”¼ë“œë°± ì—…ë°ì´íŠ¸: ì¢‹ì•„ìš” 1ê°œ, ì‹«ì–´ìš” 1ê°œ\n",
      "\n",
      "ğŸ”„ í”¼ë“œë°± ë°˜ì˜ í›„:\n",
      "Day 2: ['ì œì£¼ êµ­ì œê³µí•­', 'ìˆœì²œì—­', 'í†µì˜ì¢…í•©ë²„ìŠ¤í„°ë¯¸ë„', 'ë¶€ì‚°ì—­', 'í¬í•­ì—­']\n",
      "Day 1: ['ìƒê³„ì—­ 4í˜¸ì„ ', 'ë¨¹ê³¨ì—­ 7í˜¸ì„ ', 'ì•„ì´í…Œì½”', 'ì„œìš¸ ê°ˆì‚° ì´ˆë“±í•™êµ í›„ë¬¸', 'ì¸ì²œì—­ 1í˜¸ì„ ', 'ì™•ì‚° ë§ˆë¦¬ë‚˜í•­', 'ë§Œí˜¸ LPG ì¶©ì „ì†Œ', 'ê°€í‰íœ´ê²Œì†Œ ì¶˜ì²œ ë°©í–¥', 'ì‚°ì •í˜¸ìˆ˜ í•˜ë™ ì£¼ì°¨ì¥', 'ê°•ë¦‰ ëŒ€ê´€ë ¹íœ´ê²Œì†Œ ì¸ì²œë°©í–¥']\n"
     ]
    }
   ],
   "source": [
    "# web_inference.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import HeteroData\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "\n",
    "class ImprovedTravelGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, travel_context_dim, \n",
    "                 num_heads=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gat1 = GATConv(in_channels, hidden_channels // num_heads, \n",
    "                           heads=num_heads, dropout=dropout, concat=True)\n",
    "        self.gat2 = GATConv(hidden_channels, hidden_channels // num_heads, \n",
    "                           heads=num_heads, dropout=dropout, concat=True)\n",
    "        self.gat3 = GATConv(hidden_channels, out_channels, \n",
    "                           heads=1, dropout=dropout, concat=False)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.travel_encoder = nn.Sequential(\n",
    "            nn.Linear(travel_context_dim, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.fusion_net = nn.Sequential(\n",
    "            nn.Linear(out_channels * 2, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "        self.preference_head = nn.Sequential(\n",
    "            nn.Linear(out_channels, hidden_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_channels // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, data, travel_context, return_attention=False):\n",
    "        x = data['visit_area'].x\n",
    "        edge_index = data['visit_area', 'moved_to', 'visit_area'].edge_index\n",
    "        \n",
    "        x1 = self.gat1(x, edge_index)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = F.relu(x1)\n",
    "        x1 = self.dropout(x1)\n",
    "        \n",
    "        x2 = self.gat2(x1, edge_index)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = F.relu(x2 + x1)\n",
    "        x2 = self.dropout(x2)\n",
    "        \n",
    "        graph_embedding = self.gat3(x2, edge_index)\n",
    "        graph_embedding = self.bn3(graph_embedding)\n",
    "        \n",
    "        travel_embedding = self.travel_encoder(travel_context)\n",
    "        travel_embedding_expanded = travel_embedding.expand(graph_embedding.size(0), -1)\n",
    "        \n",
    "        fused_features = torch.cat([graph_embedding, travel_embedding_expanded], dim=1)\n",
    "        final_embedding = self.fusion_net(fused_features)\n",
    "        \n",
    "        preference_scores = self.preference_head(final_embedding)\n",
    "        \n",
    "        return final_embedding, preference_scores\n",
    "\n",
    "class TravelRecommendationSystem:\n",
    "    def __init__(self, model_path='travel_recommendation_model.pt', data_path='travel_data.pkl'):\n",
    "        \"\"\"ì›¹ìš© ì—¬í–‰ ì¶”ì²œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”\"\"\"\n",
    "        \n",
    "        print(\"ğŸš€ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...\")\n",
    "        \n",
    "        # 1. ë°ì´í„° ë¡œë“œ\n",
    "        with open(data_path, 'rb') as f:\n",
    "            self.data_dict = pickle.load(f)\n",
    "        \n",
    "        self.visit_area_df = self.data_dict['visit_area_df']\n",
    "        self.graph_data = self.data_dict['graph_data']\n",
    "        self.visit_scaler = self.data_dict['visit_scaler']\n",
    "        self.travel_scaler = self.data_dict['travel_scaler']\n",
    "        \n",
    "        # 2. ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.graph_data = self.graph_data.to(self.device)\n",
    "        \n",
    "        # 3. ëª¨ë¸ ë¡œë“œ\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        model_config = checkpoint['model_config']\n",
    "        \n",
    "        self.model = ImprovedTravelGNN(**model_config).to(self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        # 4. í”¼ë“œë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "        self.user_feedback_history = []\n",
    "        self.preference_weights = None\n",
    "        self.excluded_ids = set()\n",
    "        \n",
    "        print(\"âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "    \n",
    "    def process_travel_input(self, travel_info):\n",
    "        \"\"\"ì›¹ì—ì„œ ë°›ì€ ì—¬í–‰ ì •ë³´ ì „ì²˜ë¦¬\"\"\"\n",
    "        \n",
    "        travel_feature_cols = [\n",
    "            'TOTAL_COST_BINNED_ENCODED', 'WITH_PET', 'MONTH', 'DURATION',\n",
    "            'MVMN_ê¸°íƒ€', 'MVMN_ëŒ€ì¤‘êµí†µ', 'MVMN_ìê°€ìš©',\n",
    "            'TRAVEL_PURPOSE_1', 'TRAVEL_PURPOSE_2', 'TRAVEL_PURPOSE_3',\n",
    "            'TRAVEL_PURPOSE_4', 'TRAVEL_PURPOSE_5', 'TRAVEL_PURPOSE_6',\n",
    "            'TRAVEL_PURPOSE_7', 'TRAVEL_PURPOSE_8', 'TRAVEL_PURPOSE_9',\n",
    "            'WHOWITH_2ì¸ì—¬í–‰', 'WHOWITH_ê°€ì¡±ì—¬í–‰', 'WHOWITH_ê¸°íƒ€',\n",
    "            'WHOWITH_ë‹¨ë…ì—¬í–‰', 'WHOWITH_ì¹œêµ¬/ì§€ì¸ ì—¬í–‰'\n",
    "        ]\n",
    "        \n",
    "        processed_info = travel_info.copy()\n",
    "        \n",
    "        # ë°˜ë ¤ë™ë¬¼ ë™ë°˜\n",
    "        mission_list = processed_info['mission_ENC'].strip().split(',')\n",
    "        processed_info['WITH_PET'] = 1 if '0' in mission_list else 0\n",
    "            \n",
    "        # ì—¬í–‰ ëª©ì \n",
    "        for i in range(1, 10):\n",
    "            processed_info[f'TRAVEL_PURPOSE_{i}'] = 1 if str(i) in mission_list else 0\n",
    "            \n",
    "        # ë‚ ì§œ ì²˜ë¦¬\n",
    "        dates = processed_info['date_range'].split(' - ')\n",
    "        start_date = datetime.strptime(dates[0].strip(), \"%Y-%m-%d\")\n",
    "        end_date = datetime.strptime(dates[1].strip(), \"%Y-%m-%d\")\n",
    "        \n",
    "        processed_info['MONTH'] = end_date.month\n",
    "        processed_info['DURATION'] = max(1, (end_date - start_date).days)\n",
    "        \n",
    "        # êµí†µìˆ˜ë‹¨\n",
    "        for m in ['ìê°€ìš©', 'ëŒ€ì¤‘êµí†µ', 'ê¸°íƒ€']:\n",
    "            processed_info[f\"MVMN_{m}\"] = 0\n",
    "        \n",
    "        if processed_info['MVMN_NM_ENC'] == '1':\n",
    "            processed_info['MVMN_ìê°€ìš©'] = 1\n",
    "        elif processed_info['MVMN_NM_ENC'] == '2':\n",
    "            processed_info['MVMN_ëŒ€ì¤‘êµí†µ'] = 1\n",
    "        else:\n",
    "            processed_info['MVMN_ê¸°íƒ€'] = 1\n",
    "        \n",
    "        # ë™í–‰ì\n",
    "        whowith_onehot = [0] * 5\n",
    "        idx = int(processed_info['whowith_ENC']) - 1\n",
    "        if 0 <= idx < 5:\n",
    "            whowith_onehot[idx] = 1\n",
    "        \n",
    "        processed_info.update({\n",
    "            'WHOWITH_ë‹¨ë…ì—¬í–‰': whowith_onehot[0],\n",
    "            'WHOWITH_2ì¸ì—¬í–‰': whowith_onehot[1],\n",
    "            'WHOWITH_ê°€ì¡±ì—¬í–‰': whowith_onehot[2],\n",
    "            'WHOWITH_ì¹œêµ¬/ì§€ì¸ ì—¬í–‰': whowith_onehot[3],\n",
    "            'WHOWITH_ê¸°íƒ€': whowith_onehot[4],\n",
    "        })\n",
    "        \n",
    "        # ë¹„ìš©\n",
    "        processed_info['TOTAL_COST_BINNED_ENCODED'] = int(processed_info['TOTAL_COST'])\n",
    "        \n",
    "        # ìµœì¢… ë²¡í„° ìƒì„±\n",
    "        travel_vector = [int(processed_info.get(k, 0)) for k in travel_feature_cols]\n",
    "        \n",
    "        return np.array([travel_vector]).astype(np.float32), processed_info['DURATION']\n",
    "    \n",
    "    def get_recommendations(self, travel_info, top_k=20, diversity_weight=0.3):\n",
    "        \"\"\"ì—¬í–‰ ì¶”ì²œ ìƒì„±\"\"\"\n",
    "        \n",
    "        # 1. ì—¬í–‰ ì •ë³´ ì „ì²˜ë¦¬\n",
    "        travel_tensor, duration = self.process_travel_input(travel_info)\n",
    "        travel_context = torch.tensor(travel_tensor, dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        # 2. ëª¨ë¸ ì¶”ë¡ \n",
    "        with torch.no_grad():\n",
    "            embeddings, preference_scores = self.model(self.graph_data, travel_context)\n",
    "        \n",
    "        scores = preference_scores.squeeze()\n",
    "        \n",
    "        # 3. ì œì™¸ëœ í•­ëª©ë“¤ ë‚®ì€ ì ìˆ˜ë¡œ ì„¤ì •\n",
    "        for exclude_id in self.excluded_ids:\n",
    "            matching_indices = self.visit_area_df[\n",
    "                self.visit_area_df['NEW_VISIT_AREA_ID'] == exclude_id\n",
    "            ].index.tolist()\n",
    "            \n",
    "            for idx in matching_indices:\n",
    "                if idx < len(scores):\n",
    "                    scores[idx] = -1.0\n",
    "        \n",
    "        # 4. í”¼ë“œë°± ê¸°ë°˜ ì ìˆ˜ ì¡°ì •\n",
    "        if self.preference_weights:\n",
    "            scores = self._apply_preference_weights(scores)\n",
    "        \n",
    "        # 5. MMR ê¸°ë°˜ ë‹¤ì–‘ì„± ì¶”ì²œ\n",
    "        recommendations = self._mmr_selection(scores, embeddings, top_k, diversity_weight)\n",
    "        \n",
    "        # 6. ì¤‘ë³µ ì œê±° ë° ìœ íš¨í•œ ì¶”ì²œë§Œ ì„ íƒ\n",
    "        final_recommendations = self._filter_unique_recommendations(recommendations, max_items=15)\n",
    "        \n",
    "        # 7. ìµœì  ê²½ë¡œ ìƒì„±\n",
    "        optimized_routes = self._generate_optimized_routes(final_recommendations, duration)\n",
    "        \n",
    "        return {\n",
    "            'routes': optimized_routes,\n",
    "            'recommendations_data': final_recommendations,\n",
    "            'embeddings': embeddings,\n",
    "            'duration': duration\n",
    "        }\n",
    "    \n",
    "    def update_feedback(self, liked_items, disliked_items, embeddings):\n",
    "        \"\"\"ì‚¬ìš©ì í”¼ë“œë°± ì—…ë°ì´íŠ¸\"\"\"\n",
    "        \n",
    "        # 1. ì œì™¸ ëª©ë¡ ì—…ë°ì´íŠ¸\n",
    "        for item_id in disliked_items:\n",
    "            self.excluded_ids.add(item_id)\n",
    "        \n",
    "        # 2. í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ì €ì¥\n",
    "        feedback = {\n",
    "            'liked': liked_items,\n",
    "            'disliked': disliked_items,\n",
    "            'timestamp': datetime.now()\n",
    "        }\n",
    "        self.user_feedback_history.append(feedback)\n",
    "        \n",
    "        # 3. ì„ í˜¸ë„ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "        self.preference_weights = self._calculate_preference_weights()\n",
    "        \n",
    "        print(f\"âœ… í”¼ë“œë°± ì—…ë°ì´íŠ¸: ì¢‹ì•„ìš” {len(liked_items)}ê°œ, ì‹«ì–´ìš” {len(disliked_items)}ê°œ\")\n",
    "        \n",
    "        return len(self.excluded_ids)\n",
    "    \n",
    "    def _apply_preference_weights(self, scores):\n",
    "        \"\"\"í”¼ë“œë°± ê¸°ë°˜ ì ìˆ˜ ì¡°ì •\"\"\"\n",
    "        if not self.preference_weights:\n",
    "            return scores\n",
    "            \n",
    "        adjusted_scores = scores.clone()\n",
    "        \n",
    "        for i, row in self.visit_area_df.iterrows():\n",
    "            if i >= len(adjusted_scores):\n",
    "                break\n",
    "                \n",
    "            area_type = row.get('VISIT_AREA_TYPE_CD', 0)\n",
    "            \n",
    "            if area_type in self.preference_weights.get('preferred_types', []):\n",
    "                adjusted_scores[i] *= 1.3\n",
    "            elif area_type in self.preference_weights.get('avoided_types', []):\n",
    "                adjusted_scores[i] *= 0.7\n",
    "        \n",
    "        return adjusted_scores\n",
    "    \n",
    "    def _mmr_selection(self, scores, embeddings, top_k, diversity_weight):\n",
    "        \"\"\"MMR ê¸°ë°˜ ë‹¤ì–‘ì„± ì„ íƒ\"\"\"\n",
    "        recommendations = []\n",
    "        remaining_indices = list(range(len(scores)))\n",
    "        \n",
    "        # ì œì™¸ëœ ì¸ë±ìŠ¤ ì œê±°\n",
    "        for exclude_id in self.excluded_ids:\n",
    "            matching_indices = self.visit_area_df[\n",
    "                self.visit_area_df['NEW_VISIT_AREA_ID'] == exclude_id\n",
    "            ].index.tolist()\n",
    "            for idx in matching_indices:\n",
    "                if idx in remaining_indices:\n",
    "                    remaining_indices.remove(idx)\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ì¶”ì²œ\n",
    "        if remaining_indices:\n",
    "            valid_scores = [(i, scores[i].item()) for i in remaining_indices if scores[i].item() >= 0]\n",
    "            if valid_scores:\n",
    "                best_idx = max(valid_scores, key=lambda x: x[1])[0]\n",
    "                recommendations.append(best_idx)\n",
    "                remaining_indices.remove(best_idx)\n",
    "        \n",
    "        # ë‚˜ë¨¸ì§€ MMR ì„ íƒ\n",
    "        for _ in range(min(top_k - 1, len(remaining_indices))):\n",
    "            if not remaining_indices:\n",
    "                break\n",
    "            \n",
    "            best_score = -float('inf')\n",
    "            best_idx = None\n",
    "            \n",
    "            for idx in remaining_indices:\n",
    "                if scores[idx].item() < 0:\n",
    "                    continue\n",
    "                \n",
    "                relevance = scores[idx].item()\n",
    "                \n",
    "                # ë‹¤ì–‘ì„± ê³„ì‚°\n",
    "                similarities = []\n",
    "                for rec_idx in recommendations:\n",
    "                    sim = F.cosine_similarity(\n",
    "                        embeddings[idx:idx+1], \n",
    "                        embeddings[rec_idx:rec_idx+1]\n",
    "                    ).item()\n",
    "                    similarities.append(sim)\n",
    "                \n",
    "                diversity = 1 - max(similarities) if similarities else 1\n",
    "                final_score = (1 - diversity_weight) * relevance + diversity_weight * diversity\n",
    "                \n",
    "                if final_score > best_score:\n",
    "                    best_score = final_score\n",
    "                    best_idx = idx\n",
    "            \n",
    "            if best_idx is not None:\n",
    "                recommendations.append(best_idx)\n",
    "                remaining_indices.remove(best_idx)\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _filter_unique_recommendations(self, recommendations, max_items=10):\n",
    "        \"\"\"ì¤‘ë³µ ì œê±° ë° ìœ íš¨í•œ ì¶”ì²œ í•„í„°ë§\"\"\"\n",
    "        unique_recommendations = []\n",
    "        seen_ids = set()\n",
    "        \n",
    "        for idx in recommendations:\n",
    "            if idx < len(self.visit_area_df):\n",
    "                row = self.visit_area_df.iloc[idx]\n",
    "                area_id = row['NEW_VISIT_AREA_ID']\n",
    "                \n",
    "                if area_id not in seen_ids and area_id not in self.excluded_ids and area_id != 0:\n",
    "                    unique_recommendations.append({\n",
    "                        'idx': idx,\n",
    "                        'id': area_id,\n",
    "                        'name': row['VISIT_AREA_NM'],\n",
    "                        'coords': [row['X_COORD'], row['Y_COORD']],\n",
    "                        'type': row.get('VISIT_AREA_TYPE_CD', 0)\n",
    "                    })\n",
    "                    seen_ids.add(area_id)\n",
    "                \n",
    "                if len(unique_recommendations) >= max_items:\n",
    "                    break\n",
    "        \n",
    "        return unique_recommendations\n",
    "    \n",
    "    def _generate_optimized_routes(self, recommendations, duration):\n",
    "        \"\"\"ìµœì í™”ëœ ì¼ë³„ ê²½ë¡œ ìƒì„±\"\"\"\n",
    "        if not recommendations:\n",
    "            return {}\n",
    "        \n",
    "        coords = np.array([rec['coords'] for rec in recommendations])\n",
    "        coords = np.nan_to_num(coords, nan=0.0)\n",
    "        \n",
    "        # K-means í´ëŸ¬ìŠ¤í„°ë§\n",
    "        n_clusters = min(duration, len(recommendations))\n",
    "        if n_clusters > 1:\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "            day_labels = kmeans.fit_predict(coords)\n",
    "        else:\n",
    "            day_labels = np.zeros(len(recommendations))\n",
    "        \n",
    "        # ì¼ë³„ ê·¸ë£¹ ìƒì„±\n",
    "        daily_groups = {}\n",
    "        for i, rec in enumerate(recommendations):\n",
    "            day = int(day_labels[i])\n",
    "            if day not in daily_groups:\n",
    "                daily_groups[day] = []\n",
    "            daily_groups[day].append(rec)\n",
    "        \n",
    "        # ë‹¨ì¼ ì¥ì†Œ ì¼ì • ì¬ë°°ì¹˜\n",
    "        for day, locs in list(daily_groups.items()):\n",
    "            if len(locs) == 1 and len(daily_groups) > 1:\n",
    "                target_day = min(daily_groups.keys())\n",
    "                daily_groups[target_day].extend(locs)\n",
    "                del daily_groups[day]\n",
    "        \n",
    "        # TSP ìµœì í™”\n",
    "        optimized_routes = {}\n",
    "        for day, locations in daily_groups.items():\n",
    "            if len(locations) > 1:\n",
    "                optimized_routes[day] = self._solve_tsp_simple(locations)\n",
    "            else:\n",
    "                optimized_routes[day] = locations\n",
    "        \n",
    "        return optimized_routes\n",
    "    \n",
    "    def _solve_tsp_simple(self, locations):\n",
    "        \"\"\"ê°„ë‹¨í•œ TSP í•´ë²• (Nearest Neighbor)\"\"\"\n",
    "        if len(locations) <= 2:\n",
    "            return locations\n",
    "        \n",
    "        coords = np.array([loc['coords'] for loc in locations])\n",
    "        n = len(coords)\n",
    "        \n",
    "        # ê±°ë¦¬ í–‰ë ¬\n",
    "        dist_matrix = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                dist_matrix[i][j] = np.linalg.norm(coords[i] - coords[j])\n",
    "        \n",
    "        # Nearest Neighbor ì•Œê³ ë¦¬ì¦˜\n",
    "        unvisited = set(range(1, n))\n",
    "        current = 0\n",
    "        route = [0]\n",
    "        \n",
    "        while unvisited:\n",
    "            nearest = min(unvisited, key=lambda x: dist_matrix[current][x])\n",
    "            route.append(nearest)\n",
    "            unvisited.remove(nearest)\n",
    "            current = nearest\n",
    "        \n",
    "        return [locations[i] for i in route]\n",
    "    \n",
    "    def _calculate_preference_weights(self):\n",
    "        \"\"\"í”¼ë“œë°± íˆìŠ¤í† ë¦¬ ê¸°ë°˜ ì„ í˜¸ë„ ê°€ì¤‘ì¹˜ ê³„ì‚°\"\"\"\n",
    "        if not self.user_feedback_history:\n",
    "            return None\n",
    "        \n",
    "        liked_types = []\n",
    "        disliked_types = []\n",
    "        \n",
    "        for feedback in self.user_feedback_history:\n",
    "            for area_id in feedback['liked']:\n",
    "                matching_rows = self.visit_area_df[\n",
    "                    self.visit_area_df['NEW_VISIT_AREA_ID'] == area_id\n",
    "                ]\n",
    "                if not matching_rows.empty:\n",
    "                    liked_types.append(matching_rows.iloc[0].get('VISIT_AREA_TYPE_CD', 0))\n",
    "            \n",
    "            for area_id in feedback['disliked']:\n",
    "                matching_rows = self.visit_area_df[\n",
    "                    self.visit_area_df['NEW_VISIT_AREA_ID'] == area_id\n",
    "                ]\n",
    "                if not matching_rows.empty:\n",
    "                    disliked_types.append(matching_rows.iloc[0].get('VISIT_AREA_TYPE_CD', 0))\n",
    "        \n",
    "        return {\n",
    "            'preferred_types': list(set(liked_types)),\n",
    "            'avoided_types': list(set(disliked_types))\n",
    "        }\n",
    "    \n",
    "    def reset_feedback(self):\n",
    "        \"\"\"í”¼ë“œë°± ì´ˆê¸°í™”\"\"\"\n",
    "        self.user_feedback_history = []\n",
    "        self.preference_weights = None\n",
    "        self.excluded_ids = set()\n",
    "        print(\"ğŸ”„ í”¼ë“œë°± ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "\n",
    "# ì›¹ ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”\n",
    "    recommender = TravelRecommendationSystem()\n",
    "    \n",
    "    # ì—¬í–‰ ì •ë³´ ì˜ˆì‹œ\n",
    "    travel_example = {\n",
    "        'mission_ENC': '0,1,2',\n",
    "        'date_range': '2025-09-28 - 2025-09-30',\n",
    "        'TOTAL_COST': '2',\n",
    "        'MVMN_NM_ENC': '2',\n",
    "        'whowith_ENC': '2'\n",
    "    }\n",
    "    \n",
    "    # ì´ˆê¸° ì¶”ì²œ\n",
    "    result = recommender.get_recommendations(travel_example)\n",
    "    print(\"ğŸ—“ï¸ ì¶”ì²œ ì¼ì •:\")\n",
    "    for day, route in result['routes'].items():\n",
    "        print(f\"Day {day + 1}: {[loc['name'] for loc in route]}\")\n",
    "    \n",
    "    # í”¼ë“œë°± ì²˜ë¦¬ (ì˜ˆì‹œ)\n",
    "    liked_ids = [result['recommendations_data'][0]['id']]\n",
    "    disliked_ids = [result['recommendations_data'][1]['id']]\n",
    "    \n",
    "    recommender.update_feedback(liked_ids, disliked_ids, result['embeddings'])\n",
    "    \n",
    "    # ì¬ì¶”ì²œ\n",
    "    result2 = recommender.get_recommendations(travel_example)\n",
    "    print(\"\\nğŸ”„ í”¼ë“œë°± ë°˜ì˜ í›„:\")\n",
    "    for day, route in result2['routes'].items():\n",
    "        print(f\"Day {day + 1}: {[loc['name'] for loc in route]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
